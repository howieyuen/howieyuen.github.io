'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/kubernetes/sig-apps/k8s-apps-rolling-update/','title':"k8s应用滚动更新",'section':"sig-apps",'content':"1. 概念 #  滚动更新，通常出现在软件或者是系统中。滚动更新与传统更新的不同之处在于： 滚动更新不但提供了更新服务，而且通常还提供了滚动进度查询，滚动历史记录， 以及最重要的回滚等能力。通俗地说，就是具有系统或是软件的主动降级的能力。\n2. Deployment 滚动更新 #  Deployment 更新方式有 2 种：\n RollingUpdate Recreate  其中，滚动更新是最常见的，阅读代码 pkg/controller/deployment/deployment_controller.go:648， 可以看到 2 种方式分别对应的业务逻辑：\nfunc (dc *DeploymentController) syncDeployment(key string) error { ... switch d.Spec.Strategy.Type { case apps.RecreateDeploymentStrategyType: return dc.rolloutRecreate(d, rsList, podMap) case apps.RollingUpdateDeploymentStrategyType: return dc.rolloutRolling(d, rsList) } ... } 根据 d.Spec.Strategy.Type，若更新策略为 RollingUpdate， 则执行 dc.rolloutRecreate() 方法，具体逻辑如下：\nfunc (dc *DeploymentController) rolloutRolling(d *apps.Deployment, rsList []*apps.ReplicaSet) error { // 1、获取所有的 rs，若没有 newRS 则创建 \tnewRS, oldRSs, err := dc.getAllReplicaSetsAndSyncRevision(d, rsList, true) if err != nil { return err } allRSs := append(oldRSs, newRS) // 2、newRS 执行 scale up 操作 \tscaledUp, err := dc.reconcileNewReplicaSet(allRSs, newRS, d) if err != nil { return err } if scaledUp { // Update DeploymentStatus \treturn dc.syncRolloutStatus(allRSs, newRS, d) } // 3、oldRS 执行 scale down 操作 \tscaledDown, err := dc.reconcileOldReplicaSets(allRSs, controller.FilterActiveReplicaSets(oldRSs), newRS, d) if err != nil { return err } if scaledDown { // Update DeploymentStatus \treturn dc.syncRolloutStatus(allRSs, newRS, d) } // 4、清理过期的 rs \tif deploymentutil.DeploymentComplete(d, \u0026amp;d.Status) { if err := dc.cleanupDeployment(oldRSs, d); err != nil { return err } } // 5、同步 deployment 状态 \treturn dc.syncRolloutStatus(allRSs, newRS, d) } 2.1 滚动更新概述 #  上面代码中 5 个重要的步骤总结如下：\n 调用 getAllReplicaSetsAndSyncRevision() 获取所有的 rs，若没有 newRS 则创建； 调用 reconcileNewReplicaSet() 判断是否需要对 newRS 进行 scaleUp 操作；如果需要 scaleUp，更新 Deployment 的 status， 添加相关的 condition，该 condition 的 type 是 Progressing，表明该 deployment 正在更新中，然后直接返回； 调用 reconcileOldReplicaSets() 判断是否需要为 oldRS 进行 scaleDown 操作；如果需要 scaleDown， 把 oldRS 关联的 pod 删掉 maxScaledDown 个，然后更新 Deployment 的 status，添加相关的 condition，直接返回。 这样一来就保证了在滚动更新过程中，新老版本的 Pod 都存在； 如果两者都不是则滚动升级很可能已经完成，此时需要检查 deployment.Status 是否已经达到期望状态， 并且根据 deployment.Spec.RevisionHistoryLimit 的值清理 oldRSs； 最后，同步 deployment 的状态，使其与期望一致；  从上面的步骤可以看出，滚动更新的过程主要分成一下三个阶段：\n mermaid.initialize({ \"flowchart\": { \"useMaxWidth\":true }, \"theme\": \"default\" } ) graph LR\rstart((开始)) -- condtion1{newRS need scale up ?}\rcondtion1 -- No -- condtion2{oldRS need scale down ?}\rcondtion2 -- NO -- x3(3. sync deploment status)\rcondtion1 -- YES -- x1(1. newRS scale up)\rx1 -- stop((结束))\rcondtion2 -- YES -- x2(2. oldRS scale down)\rx2 -- stop\rx3 -- stop\r2.1.1 newRS scale up #  阅读代码 pkg/controller/deployment/rolling.go:68，详细如下：\nfunc (dc *DeploymentController) reconcileNewReplicaSet(allRSs []*apps.ReplicaSet, newRS *apps.ReplicaSet, deployment *apps.Deployment) (bool, error) { // 1、判断副本数是否已达到了期望值 \tif *(newRS.Spec.Replicas) == *(deployment.Spec.Replicas) { // Scaling not required. \treturn false, nil } // 2、判断是否需要 scale down 操作 \tif *(newRS.Spec.Replicas) \u0026gt; *(deployment.Spec.Replicas) { // Scale down. \tscaled, _, err := dc.scaleReplicaSetAndRecordEvent(newRS, *(deployment.Spec.Replicas), deployment) return scaled, err } // 3、计算 newRS 所需要的副本数 \tnewReplicasCount, err := deploymentutil.NewRSNewReplicas(deployment, allRSs, newRS) if err != nil { return false, err } // 4、如果需要 scale ，则更新 rs 的 annotation 以及 rs.Spec.Replicas \tscaled, _, err := dc.scaleReplicaSetAndRecordEvent(newRS, newReplicasCount, deployment) return scaled, err } 从上面的源码可以得出，reconcileNewReplicaSet() 的主要逻辑如下：\n 判断 newRS.Spec.Replicas 和 deployment.Spec.Replicas 是否相等， 如果相等则直接返回，说明已经达到期望状态； 若 newRS.Spec.Replicas \u0026gt; deployment.Spec.Replicas， 则说明 newRS 副本数已经超过期望值，调用 dc.scaleReplicaSetAndRecordEvent() 进行 scale down； 此时 newRS.Spec.Replicas \u0026lt; deployment.Spec.Replicas， 调用 deploymentutil.NewRSNewReplicas() 为 newRS 计算所需要的副本数， 计算原则遵守 maxSurge 和 maxUnavailable 的约束； 调用 dc.scaleReplicaSetAndRecordEvent() 更新 newRS 对象，设置 rs.Spec.Replicas、rs.Annotations[DesiredReplicasAnnotation] 以及 rs.Annotations[MaxReplicasAnnotation]；  其中，计算 newRS 的副本数，是滚动更新核心过程的第一步， 阅读源码 pkg/controller/deployment/util/deployment_util.go:816：\nfunc NewRSNewReplicas(deployment *apps.Deployment, allRSs []*apps.ReplicaSet, newRS *apps.ReplicaSet) (int32, error) { switch deployment.Spec.Strategy.Type { case apps.RollingUpdateDeploymentStrategyType: // 1、计算 maxSurge 值，向上取整 \tmaxSurge, err := intstrutil.GetValueFromIntOrPercent(deployment.Spec.Strategy.RollingUpdate.MaxSurge, int(*(deployment.Spec.Replicas)), true) if err != nil { return 0, err } // 2、累加 rs.Spec.Replicas 获取 currentPodCount \tcurrentPodCount := GetReplicaCountForReplicaSets(allRSs) maxTotalPods := *(deployment.Spec.Replicas) + int32(maxSurge) if currentPodCount \u0026gt;= maxTotalPods { // Cannot scale up. \treturn *(newRS.Spec.Replicas), nil } // 3、计算 scaleUpCount，结果不超过期望值 \tscaleUpCount := maxTotalPods - currentPodCount scaleUpCount = int32(integer.IntMin(int(scaleUpCount), int(*(deployment.Spec.Replicas)-*(newRS.Spec.Replicas)))) return *(newRS.Spec.Replicas) + scaleUpCount, nil case apps.RecreateDeploymentStrategyType: return *(deployment.Spec.Replicas), nil default: return 0, fmt.Errorf(\u0026#34;deployment type %v isn\u0026#39;t supported\u0026#34;, deployment.Spec.Strategy.Type) } } 可知 NewRSNewReplicas() 的主要逻辑如下：\n 判断更新策略； 计算 maxSurge 值； 通过 allRSs 计算 currentPodCount 的值； 最后计算 scaleUpCount 值；  2.1.2 oldRS scale down #  同理，oldRS 规模缩小，阅读源码 pkg/controller/deployment/rolling.go:68:\nfunc (dc *DeploymentController) reconcileOldReplicaSets(allRSs []*apps.ReplicaSet, oldRSs []*apps.ReplicaSet, newRS *apps.ReplicaSet, deployment *apps.Deployment) (bool, error) { // 1、计算 oldPodsCount \toldPodsCount := deploymentutil.GetReplicaCountForReplicaSets(oldRSs) if oldPodsCount == 0 { // Can\u0026#39;t scale down further \treturn false, nil } // 2、计算 maxUnavailable \tallPodsCount := deploymentutil.GetReplicaCountForReplicaSets(allRSs) klog.V(4).Infof(\u0026#34;New replica set %s/%s has %d available pods.\u0026#34;, newRS.Namespace, newRS.Name, newRS.Status.AvailableReplicas) maxUnavailable := deploymentutil.MaxUnavailable(*deployment) // 3、计算 maxScaledDown \tminAvailable := *(deployment.Spec.Replicas) - maxUnavailable newRSUnavailablePodCount := *(newRS.Spec.Replicas) - newRS.Status.AvailableReplicas maxScaledDown := allPodsCount - minAvailable - newRSUnavailablePodCount if maxScaledDown \u0026lt;= 0 { return false, nil } // 4、清理异常的 rs \toldRSs, cleanupCount, err := dc.cleanupUnhealthyReplicas(oldRSs, deployment, maxScaledDown) if err != nil { return false, nil } klog.V(4).Infof(\u0026#34;Cleaned up unhealthy replicas from old RSes by %d\u0026#34;, cleanupCount) // 5、缩容 old rs \tallRSs = append(oldRSs, newRS) scaledDownCount, err := dc.scaleDownOldReplicaSetsForRollingUpdate(allRSs, oldRSs, deployment) if err != nil { return false, nil } klog.V(4).Infof(\u0026#34;Scaled down old RSes of deployment %s by %d\u0026#34;, deployment.Name, scaledDownCount) totalScaledDown := cleanupCount + scaledDownCount return totalScaledDown \u0026gt; 0, nil } 通过上面的代码可知，reconcileOldReplicaSets() 的主要逻辑如下：\n 通过 oldRSs 和 allRSs 获取 oldPodsCount 和 allPodsCount； 计算 deployment 的 maxUnavailable、minAvailable、newRSUnavailablePodCount、maxScaledDown 值， 当 deployment 的 maxSurge 和 maxUnavailable 值为百分数时， 计算 maxSurge 向上取整而 maxUnavailable 则向下取整； 清理异常的 rs； 计算 oldRS 的 scaleDownCount； 最后 oldRS 缩容；  2.2 滚动更新总结 #  通过上面的代码可以看出，滚动更新过程中主要是通过调用 reconcileNewReplicaSet() 对 newRS 不断扩容， 调用 reconcileOldReplicaSets() 对 oldRS 不断缩容，最终达到期望状态，并且在整个升级过程中， 都严格遵守 maxSurge 和 maxUnavailable 的约束。\n不论是在 scale up 或者 scale down 中都是调用 scaleReplicaSetAndRecordEvent() 执行， 而 scaleReplicaSetAndRecordEvent() 又会调用 scaleReplicaSet()， 扩缩容都是更新 rs.Annotations 以及 rs.Spec.Replicas。\n整体流程如下图所示：\ngraph LR\rop1(newRS scale up) -- op3[dc.scaleReplicaSetAndRecordEvent]\rop2(oldRS scale down) -- op3(dc.scaleReplicaSetAndRecordEvent)\rop3(dc.scaleReplicaSetAndRecordEvent) -- op4(dc.scaleReplicaSet)\r2.3 滚动更新示例 #  "});index.add({'id':1,'href':'/docs/kubernetes/sig-api-machinery/key-design-of-etcd-watch/','title':"ETCD watch 关键设计",'section':"sig-api-machinery",'content':" 注：本文转自 图解kubernetes中基于etcd的watch关键设计\n 本文介绍了 kubernetes 针对 etcd 的 watch 场景，k8s 在性能优化上面的一些设计， 逐个介绍缓存、定时器、序列化缓存、bookmark 机制、forget 机制、 针对数据的索引与 ringbuffer 等组件的场景以及解决的问题， 希望能帮助到那些对 apiserver 中的 watch 机制实现感兴趣的朋友。\n1. 事件驱动与控制器 #   k8s 中并没有将业务的具体处理逻辑耦合在 rest 接口中，rest 接口只负责数据的存储， 通过控制器模式，分离数据存储与业务逻辑的耦合，保证 apiserver 业务逻辑的简洁。\n 控制器通过 watch 接口来感知对应的资源的数据变更，从而根据资源对象中的期望状态与当前状态之间的差异， 来决策业务逻辑的控制，watch 本质上做的事情其实就是将感知到的事件发生给关注该事件的控制器。\n2. Watch 的核心机制 #  这里我们先介绍基于 etcd 实现的基础的 watch 模块。\n2.1 事件类型与 etcd #   一个数据变更本质上无非就是三种类型：新增、更新和删除， 其中新增和删除都比较容易因为都可以通过当前数据获取，而更新则可能需要获取之前的数据， 这里其实就是借助了 etcd 中 revision 和 mvcc 机制来实现，这样就可以获取到之前的状态和更新后的状态， 并且获取后续的通知。\n2.2 事件管道 #   事件管道则是负责事件的传递，在 watch 的实现中通过两级管道来实现消息的分发， 首先通过 watch etcd 中的 key 获取感兴趣的事件，并进行数据的解析， 完成从bytes到内部事件的转换并且发送到输入管道(incomingEventChan)中， 然后后台会有线程负责输入管道中获取数据，并进行解析发送到输出管道(resultChan)中， 后续会从该管道来进行事件的读取发送给对应的客户端。\n2.3 事件缓冲区 #  事件缓冲区是指的如果对应的事件处理程序与当前事件发生的速率不匹配的时候， 则需要一定的 buffer 来暂存因为速率不匹配的事件， 在 go 里面大家通常使用一个有缓冲的 channel 构建。\n 到这里基本上就实现了一个基本可用的 watch 服务，通过 etcd 的 watch 接口监听数据， 然后启动独立 goroutine 来进行事件的消费，并且发送到事件管道供其他接口调用。\n3. Cacher #  kubernetes 中所有的数据和系统都基于 etcd 来实现，如何减轻访问压力呢， 答案就是缓存，watch 也是这样，本节我们来看看如何实现 watch 缓存机制的实现， 这里的 cacher 是针对 watch 的。\n3.1 Reflector #   Reflector 是 client-go 中的一个组件，其通过listwatch接口获取数据存储在自己内部的 store 中， cacher中通过该组件对 etcd 进行 watch 操作，避免为每个组件都创建一个 etcd 的 watcher。\n3.2 watchCache #   wacthCache 负责存储 watch 到的事件，并且将 watch 的事件建立对应的本地索引缓存， 同时在构建 watchCache 还负责将事件的传递， 其将 watch 到的事件通过 eventHandler 来传递给上层的 Cacher 组件。\n3.3 cacheWatcher #   cacheWatcher 顾名思义其是就是针对 cache 的一个 watcher(watch.Interface)实现， 前端的 watchServer 负责从 ResultChan 里面获取事件进行转发。\n3.4 Cacher #   Cacher 基于 etcd 的 store 结合上面的 watchCache 和 Reflector 共同构建带缓存的 REST store， 针对普通的增删改功能其直接转发给 etcd 的 store 来进行底层的操作，而对于 watch 操作则进行拦截， 构建并返回 cacheWatcher 组件。\n4. Cacher的优化 #  看完基础组件的实现，接着我们看下针对watch这个场景k8s中还做了那些优化，学习针对类似场景的优化方案。\n4.1 序列化缓存 #   如果我们有多个 watcher 都 wacth 同一个事件，在最终的时候我们都需要进行序列化， cacher 中在分发的时候，如果发现超过指定数量的watcher， 则会在进行 dispatch 的时候， 为其构建构建一个缓存函数，针对多个 watcher 只会进行一次的序列化。\n4.2 nonblocking #   在上面我们提到过事件缓冲区，但是如果某个 watcher 消费过慢依然会影响事件的分发， 为此 cacher 中通过是否阻塞(是否可以直接将数据写入到管道中)来将 watcher 分为两类， 针对不能立即投递事件的 watcher， 则会在后续进行重试。\n4.3 TimeBudget #  针对阻塞的 watcher 在进行重试的时候，会通过 dispatchTimeoutBudget 构建一个定时器来进行超时控制， 那什么叫 Budget 呢，其实如果在这段时间内，如果重试立马就成功，则本次剩余的时间， 在下一次进行定时的时候，则可以使用之前剩余的余额，但是后台也还有个线程，用于周期性重置。\n4.4 forget机制 #   针对上面的 TimeBudget 如果在给定的时间内依旧无法进行重试成功， 则就会通过 forget 来删除对应的 watcher， 由此针对消费特别缓慢的 watcher 则可以通过后续的重试来重新建立 watch， 从而减小对a piserver 的 watch 压力。\n4.5 bookmark 机制 #   bookmark机制是大阿里提供的一种优化方案，其核心是为了避免单个某个资源一直没有对应的事件， 此时对应的 informer 的 revision 会落后集群很大， bookmark 通过构建一种 BookMark 类型的事件来进行 revision 的传递， 从而让 informer 在重启后不至于落后特别多。\n4.6 watchCache 中的 ringbuffer #   watchCache 中通过 store 来构建了对应的索引缓存，但是在 listwatch 操作的时候， 则通常需要获取某个 revision 后的所有数据， 针对这类数据 watchCache 中则构建了一个 ringbuffer 来进行历史数据的缓存。\n5. 设计总结 #   本文介绍了 kubernetes 针对 etcd 的 watch 场景，k8s 在性能优化上面的一些设计， 逐个介绍缓存、定时器、序列化缓存、bookmark 机制、forget 机制、 针对数据的索引与 ringbuffer 等组件的场景以及解决的问题， 希望能帮助到那些对 apiserver 中的 watch 机制实现感兴趣的朋友。\n"});index.add({'id':2,'href':'/docs/kubernetes/sig-node/topology-manager/','title':"kubelet topology manager",'section':"sig-node",'content':" 注：本文翻译自 Node Topology Manager\n 1. 概要 #  越来越多的系统将 CPU 和硬件加速器组合使用，以支撑高延迟和搞吞吐量的并行计算。 包括电信、科学计算、机器学习、金融服务和数据分析等领域的工作。这种的混血儿构成了一个高性能环境。\n为了达到最优性能，需要对 CPU 隔离、内存和设备的物理位置进行优化。 然而，在 kubernetes 中，这些优化没有一个统一的组件管理。\n本次建议提供一个新机制，可以协同kubernetes各个组件，对硬件资源的分配可以有不同的细粒度。\n2. 启发 #  当前，kubelet 中多个组件决定系统拓扑相关的分配：\n CPU 管理器  CPU 管理器限制容器可以使用的 CPU。该能力，在 1.8 只实现了一种策略——静态分配。 该策略不支持在容器的生命周期内，动态上下线 CPU。   设备管理器  设备管理器将某个具体的设备分配给有该设备需求的容器。设备通常是在外围互连线上。 如果设备管理器和 CPU 管理器策略不一致，那么CPU和设备之间的所有通信都可能导致处理器互连结构上的额外跳转。   容器运行时（CNI）  网络接口控制器，包括 SR-IOV 虚拟功能（VF）和套接字有亲和关系，socket 不同，性能不同。    相关问题：\n  节点层级的硬件拓扑感知（包括 NUMA）  发现节点的 NUMA 架构  绑定特定 CPU 支持虚拟函数  提议：CPU 亲和与 NUMA 拓扑感知  注意，以上所有的关注点都只适用于多套接字系统。 内核能从底层硬件接收精确的拓扑信息（通常是通过 SLIT 表），是正确操作的前提。 更多信息请参考ACPI规范的 5.2.16 和 5.2.17节。\n2.1 目标 #   根据 CPU 管理器和设备管理器的输入，给容器选择最优的 NUMA 亲和节点。 集成 kubelet 中其他支持拓扑感知的组件，提供一个统一的内部接口。  2.2 非目标 #   设备间连接：根据直接设备互连来决定设备分配。此问题不同于套接字局部性。设备间的拓扑关系， 可以都在设备管理器中考虑，可以做到套接字的亲和性。实现这一策略，可以从逐渐支持任何设备之间的拓扑关系。 大页：本次提议有 2 个前提，一是集群中的节点已经预分配了大页； 二是操作系统能给容器做好本地页分配（只需要本地内存节点上有空闲的大页即可）。 容器网络接口：本次提议不包含修改 CNI。但是，如果 CNI 后续支持拓扑管理， 此次提出的方案应该具有良好的扩展性，以适配网络接口的局部性。对于特殊的网络需求， 可以使用设备插件API作为临时方案，以减少网络接口的局限性。  2.3 用户故事 #  故事1: 快速虚拟化的网络功能\n要求在一个首选的 NUMA 节点上，既要“网络快”，又能自动完成各个组件（大页，cpu 集，网络设备）的协同。 在大多数场景下，只有极少数的 NUMA 节点才能满足。\n故事2: 加速神经网络训练\nNUMA 节点中的已分配的 CPU 和设备，可满足神经网络训练的加速器和独占的CPU的需求，以达到性能最优。\n3. 提议 #  主要思想：两相拓扑一致性协议 拓扑亲和性在容器级别，与设备和 CPU 的亲和类似。在 Pod 准入期间， 一个新组件可以从设备管理器和 CPU 管理器收集 Pod 中每个容器的配置，这个组件名为拓扑管理器。 当这些组件进行资源分配时，拓扑管理器扮演本地对齐的预分配角色。 我们希望各个组件能利用 Pod 中隐含的 QoS 类型进行优先级排序，以满足局部重要性最优。\n3.1 提议修改点 #  3.1.1 新概念：拓扑管理器 #  这个提议主要关注 kubelet 中一个新组件，叫做拓扑管理器。拓扑管理器实现了 Pod 的 Admit() 接口， 并参与 kubelet 的对 Pod 的准入。当 Admit() 方法被调用，拓扑管理器根据 kubelet 标志， 逐个 Pod 或逐个容器收集 kubelet 其他组件的的拓扑信息。\n如果提示不兼容，拓扑管理器可以选择拒绝 Pod，这是由 kubelet 配置的拓扑策略所决定的。 拓扑管理器支持4中策略：none（默认）、best-erffort、restricted 和 single-numa-node。\n拓扑信息中包含了对本地资源的偏好。拓扑信息当前由以下组成：\n 位掩码表——可能满足请求的 NUMA 节点 首选属性  属性定义如下：  每个拓扑信息提供者，都有一个满足请求的可能资源分配，这样就可以尽可能减少NUMA节点数量（节点为空那样计算） 有一种可能的分配方式，相关NUMA节点联合总量，不大于任何个单个资源的的请求量      3.1.1.1 Pod 的有效资源请求/限制 #  所有提供拓扑信息的组件，都应该先考虑资源的请求和限制，再计算得出可靠的拓扑提示， 这个规则是由 init 容器的概念定义的。\nPod 对资源的请求和限制的有效值，由以下 2 个条件中较大的一个决定：\n 所有 init 容器中，请求或限制的最大值（max([]initcontainer.Request)，max([]initcontainer.Limit)） 所有应用的请求和限制的总和（sum([]containers.Request)，sum([]containers.Limit)）  下面这个例子简要说明它是如何工作的：\napiVersion: v1 kind: Pod metadata: name: example spec: containers: - name: appContainer1 resources: requests: cpu: 2 memory: 1G - name: appContainer2 resources: requests: cpu: 1 memory: 1G initContainers: - name: initContainer1 resources: requests: cpu: 2 memory: 1G - name: initContainer2 resources: requests: cpu: 2 memory: 3G #资源请求的有效值: CPU: 3, Memory: 3G debug/ephemeral 容器不能指定资源请求/限制，因为不会影响拓扑提示的结果。\n3.1.1.2 范围 #  拓扑管理器将根据新 kubelet 标志 --topology-manager-scope 的值， 尝试逐个 Pod 或逐个容器地对资源进行对齐。该标志可以显示的值详细如下:\ncontainer(默认)：逐个容器地收集拓扑信息。 然后，拓扑策略将为每个容器单独调整资源，只有调整成功，Pod 准入成功。\nPod：逐个 Pod 地收集拓扑信息。 然后，拓扑策略将为所有容器集体调整资源，只有调整成功，Pod 准入成功。\n3.1.1.3 策略 #  none(默认)：kubelet 不会参考拓扑管理器的决定\nbest-effort：拓扑管理器会基于拓扑信息，给出首选分配。 在此策略下，即使分配结果不合理，Pod 也成功准入。\nrestricted：与 best-effort 不同，在此策略下，如果分配结果不合理，Pod 会被拒绝。 同时，因准入失败，进入 Terminated 状态。\nsingle-numa-node：拓扑管理器会在 NUMA 节点上强制执行资源分配，如果分配失败，Pod 会被拒绝。 同时，因准入失败，进入 Terminated 状态。\n拓扑管理器组件默认被禁用，直到从 alpha 到 beta 级别解禁。\n3.1.1.4 亲和计算 #  拓扑管理策略基于收集的所有拓扑信息，执行亲和计算，然后决定接受或拒绝 Pod。\n3.1.1.4.1 亲和算法 #   best-effort/restricted (亲和算法相同)   循环遍历所有拓扑信息提供者，并以列表保存每个信息源的返回。 遍历步骤1中的列表，执行按位与运算，合并为单个亲和信息。 如果循环中任何字段的亲和返回了 false，则最终结果该字段也为 false。 返回的亲和信息的最小集，最小集意味着至少有一个 NUMA 节点满足资源请求。 如果没有找到任何 NUMA 节点集的提示，则返回一个默认提示，该值包含了所有 NUMA 节点，并把首选设置为false。   single-numa-node   循环遍历所有拓扑信息提供者，并以列表保存每个信息源的返回 过滤步骤 1 中累积的列表，使其只包含具有单个 NUMA 节点和空 NUMA 节点的提示 遍历步骤 1 中的列表，执行按位与运算，合并为单个亲和信息。 如果循环中任何字段的亲和返回了 false，则最终结果该字段也为false 如果没有找到具有单 NUMA 节点集的提示，则返回一个默认提示， 该提示包含所有NUMA节点集并且首选设置为 false。  3.1.1.4.2 策略决断 #   best-effort  总是遵循拓扑信息提示，准入 Pod   restricted  只有拓扑提示的首选字段为 true，才准入 Pod   single-numa-node  既需要拓扑的首选字段为 true，又需要位掩码设置为单个 NUMA 节点，才准入 Pod    3.1.1.5 新的接口 #  清单: 拓扑管理器和相关接口\npackage bitmask // BitMask interface allows hint providers to create BitMasks for TopologyHints type BitMask interface { Add(sockets ...int) error Remove(sockets ...int) error And(masks ...BitMask) Or(masks ...BitMask) Clear() Fill() IsEqual(mask BitMask) bool IsEmpty() bool IsSet(socket int) bool IsNarrowerThan(mask BitMask) bool String() string Count() int GetSockets() []int } func NewBitMask(sockets ...int) (BitMask, error) { ... } package topologymanager // Manager interface provides methods for Kubelet to manage Pod topology hints type Manager interface { // Implements Pod admit handler interface  lifecycle.PodAdmitHandler // Adds a hint provider to manager to indicate the hint provider  //wants to be consoluted when making topology hints  AddHintProvider(HintProvider) // Adds Pod to Manager for tracking  AddContainer(Pod *v1.Pod, containerID string) error // Removes Pod from Manager tracking  RemoveContainer(containerID string) error // Interface for storing Pod topology hints  Store } // TopologyHint encodes locality to local resources. Each HintProvider provides // a list of these hints to the TopoologyManager for each container at Pod // admission time. type TopologyHint struct { NUMANodeAffinity bitmask.BitMask // Preferred is set to true when the BitMask encodes a preferred  // allocation for the Container. It is set to false otherwise.  Preferred bool } // HintProvider is implemented by Kubelet components that make // topology-related resource assignments. The Topology Manager consults each // hint provider at Pod admission time. type HintProvider interface { // GetTopologyHints returns a map of resource names with a list of possible  // resource allocations in terms of NUMA locality hints. Each hint  // is optionally marked \u0026#34;preferred\u0026#34; and indicates the set of NUMA nodes  // involved in the hypothetical allocation. The topology manager calls  // this function for each hint provider, and merges the hints to produce  // a consensus \u0026#34;best\u0026#34; hint. The hint providers may subsequently query the  // topology manager to influence actual resource assignment.  GetTopologyHints(Pod v1.Pod, containerName string) map[string][]TopologyHint // GetPodLevelTopologyHints returns a map of resource names with a list of  // possible resource allocations in terms of NUMA locality hints.  // The returned map contains TopologyHint of requested resource by all containers  // in a Pod spec.  GetPodLevelTopologyHints(Pod *v1.Pod) map[string][]TopologyHint // Allocate triggers resource allocation to occur on the HintProvider after  // all hints have been gathered and the aggregated Hint is available via a  // call to Store.GetAffinity().  Allocate(Pod *v1.Pod, container *v1.Container) error } // Store manages state related to the Topology Manager. type Store interface { // GetAffinity returns the preferred affinity as calculated by the  // TopologyManager across all hint providers for the supplied Pod and  // container.  GetAffinity(PodUID string, containerName string) TopologyHint } // Policy interface for Topology Manager Pod Admit Result type Policy interface { // Returns Policy Name  Name() string // Returns a merged TopologyHint based on input from hint providers  // and a Pod Admit Handler Response based on hints and policy type  Merge(providersHints []map[string][]TopologyHint) (TopologyHint, lifecycle.PodAdmitResult) } 图：拓扑管理器组件\n 图：拓扑管理器实例化并出现在Pod准入生命周期中\n 3.1.2 特性门禁和kubelet启动参数 #  将添加一个特性门禁，控制拓扑管理器特性的启动。此门禁将在 Kubelet 启用，并在 Alpha 版本中默认关闭。\n  门禁定义建议：\n--feature-gate=TopologyManager=true\n  如上所述，kubelet 还新增一个标志，用于标识拓扑管理器策略。默认策略将会是 none。\n  策略标志建议：\n--topology-manager-policy=none|best-effort|restricted|single-numa-node\n  根据选择的策略，以下标志将确定应用策略的范围（逐个 Pod 或逐个容器）。范围的默认值是 container\n  范围标志建议：\n--topology-manager-scope=container|Pod\n  3.1.3 现有组件变更 #    Kubelet 向拓扑管理器咨询 Pod 准入(上面讨论过)\n  添加两个拓扑管理器接口的实现和一个特性门禁\n 当功能门被禁用时，尽可能保证拓扑管理器功能失效。 添加一个功能性拓扑管理器，用来查询拓扑信息，以便为每个容器计算首选套接字掩码。    CPU 管理器添加 2 个方法：GetTopologyHints() 和 GetPodLevelTopologyHints()\n CPU 管理器的 static 策略在决定 CPU 的亲和性是，调用拓扑管理器的 GetAffinity() 方法    设备管理器添加 2 个方法：GetTopologyHints() 和 GetPodLevelTopologyHints()\n 在设备插件接口的设备结构中添加 TopologyInfo。 插件在枚举受支持的设备时应该能够确定 NUMA 节点。请参阅下面的协议差异。 设备管理器决定设备分配时，调用拓扑管理器的 GetAffinity() 方法    清单: 修改后的设备插件 gRPC 协议\ndiff --git a/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto b/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto index efbd72c133..f86a1a5512 100644 --- a/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto +++ b/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto @@ -73,6 +73,10 @@ message ListAndWatchResponse {  repeated Device devices = 1; } +message TopologyInfo { + repeated NUMANode nodes = 1; +} + +message NUMANode { + int64 ID = 1; +} +  /* E.g: * struct Device { * ID: \u0026#34;GPU-fef8089b-4820-abfc-e83e-94318197576e\u0026#34;, * State: \u0026#34;Healthy\u0026#34;, + * Topology: + * Nodes: + * ID: 1 @@ -85,6 +89,8 @@ message Device {  string ID = 1; // Health of the device, can be healthy or unhealthy, see constants.go string health = 2; +\t// Topology details of the device +\tTopologyInfo topology = 3;  } 图：拓扑管理器提示提供者注册\n 图：拓扑管理器从HintProvider获取拓扑提示\n 此外，我们提议将设备插件接口扩展为“最后一级”过滤器，以帮助影响设备管理器做出的总体分配决策。 下面的差异显示了提议的改动：\ndiff --git a/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto b/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto index 758da317fe..1e55d9c541 100644 --- a/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto +++ b/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto @@ -55,6 +55,11 @@ service DevicePlugin {  // returns the new list rpc ListAndWatch(Empty) returns (stream ListAndWatchResponse) {} + // GetPreferredAllocation returns a preferred set of devices to allocate + // from a list of available ones. The resulting preferred allocation is not + // guaranteed to be the allocation ultimately performed by the + // `devicemanager`. It is only designed to help the `devicemanager` make a + // more informed allocation decision when possible. + rpc GetPreferredAllocation(PreferredAllocationRequest) returns (PreferredAllocationResponse) {} +  // Allocate is called during container creation so that the Device // Plugin can run device specific operations and instruct Kubelet // of the steps to make the Device available in the container @@ -99,6 +104,31 @@ message PreStartContainerRequest {  message PreStartContainerResponse { } +// PreferredAllocationRequest is passed via a call to +// `GetPreferredAllocation()` at Pod admission time. The device plugin should +// take the list of `available_deviceIDs` and calculate a preferred allocation +// of size `size` from them, making sure to include the set of devices listed +// in `must_include_deviceIDs`. +message PreferredAllocationRequest { + repeated string available_deviceIDs = 1; + repeated string must_include_deviceIDs = 2; + int32 size = 3; +} + +// PreferredAllocationResponse returns a preferred allocation, +// resulting from a PreferredAllocationRequest. +message PreferredAllocationResponse { + ContainerAllocateRequest preferred_allocation = 1; +} +  // - Allocate is expected to be called during Pod creation since allocation // failures for any container would result in Pod startup failure. // - Allocate allows kubelet to exposes additional artifacts in a Pod\u0026#39;s 使用这个新的 API 调用，设备管理器将在 Pod 准入时调用一个插件， 要求它从可用设备列表中获得一个给定大小的首选设备分配。Pod 中的每个容器都会调用一次。\n传给 GetPreferredAllocation() 方法的可用设备列表不一定与系统上可用的完整列表相匹配。 相反，在考虑所有 TopologyHint 之后，设备管理器调用 GetPreferredAllocation() 方法， 是最后一次筛选，方法执行结束必须要做出选择。因此，这个可用列表已经经过 TopologyHint 的预筛选。\n首选分配并不保证是最终由设备管理器执行的分配。它的设计只是为了帮助设备管理者在可能的情况下做出更明智的分配决策。\n在决定首选分配时，设备插件可能会考虑设备管理器不知道的内部拓扑约束。分配 NVIDIA 图形处理器对， 总是包括一个 NVLINK，就是一个很好的例子。\n在一台 8 GPU 的机器上，如果需要 2 个 GPU，NVLINK 提供的最佳连接对可能是：\n{{0,3}, {1,2}, {4,7}, {5,6}} 使用 GetPreferredAllocation () ，NVIDIA 设备插件可以将这些首选分配之一转发给设备管理器， 如果仍然有合适的设备集可用的话。如果没有这些额外的信息， 设备管理器最终会在 TopologyHint 过滤之后从可用的 gpu 列表中随机选择 gpu。 这个 API 允许它最终以最小的成本执行更好的分配。\n"});index.add({'id':3,'href':'/docs/kubernetes/sig-scheduling/advanced-scheduling/','title':"高级调度",'section':"sig-scheduling",'content':"1. 使用 taint 和 toleration 阻止节点调度到特定节点 #  1.1 taint 和 toleration #  taint，是在不修改已有 Pod 的前提下，通过在节点上添加污点信息，拒绝 Pod 的部署。 只有当一个 Pod 容忍某个节点的 taint 时，才能被调度到此节点上。\n显示节点 taint 信息\nkubectl describe node master.k8s ... Name: master.k8s Role: Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/hostname=master.k8s Annotations: node.alpha.kubernetes.io/ttl=0 Taints: node-role.kubernetes.io/master:NoSchedule ... 主节点上包含一个污点，污点包含一个 key 和 value，以及一个 effect，格式为=:。 上面的污点信息表示，key 为 node-role.kubernetes.io/master，value 是空，effect 是 NoSchedule。\n显示 Pod tolerations\nkubectl describe Pod kube-proxy-as92 -n kube-system ... Tolerations: node-role.kubernetes.io/master:=NoSchedule node.alpha.kubernetes.io/notReady=:Exists:NoExecute node.alpha.kubernetes.io/unreachable=:Exists:NoExecute ... 第一个 toleration 匹配了主节点的 taint，表示允许这个 Pod 调度到主节点上。\n了解污点效果 另外 2 个在 kube-proxy Pod 上容忍定义了当前节点状态是没有 ready 或者是 unreachable 时， 该 Pod 允许运行在该节点上多长时间。污点可以包含以下三种效果：\n NoSchedule，表示如果pod没有容忍此污点，将无法调度 PreferNoSchedule，是上面的宽松版本，如果没有其他节点可调度，依旧可以调度到本节点 NoExecute，上 2 个在调度期间起作用，而此设定也会影响正在运行中的 Pod。 如果节点上的 Pod 没有容忍此污点，会被驱逐。  1.2 在节点上定义污点 #  kubectl taint node node1.k8s node-type=production:NoSchedule 此命令给节点添加污点，key 为 node-type，value 为 production，effect 为 NoSchedule。 如果现在部署一个常规 Pod 多个副本，没有一个 Pod 会调度到此节点上。\n1.3 在 Pod 上添加容忍 #  apiVersion: apps/v1 kind: Deployment metadata: name: prod spec: replicas: 5 template: spec: ... tolertations: - key: node-type operator: Equals value: production effect: NoSchedule 部署此 deployment，Pod 即可调度到 node1.k8s 节点上。\n1.4 了解污点和容忍的使用场景 #  调度时使用污点和容忍\n污点可以组织新 Pod 的调度，或者定义非有限调度节点，甚至是将已有 Pod 驱逐。 例如，一个集群分成多个部分，只允许开发团队将 Pod 部署到特定节点上；或者某些特殊 Pod 依赖硬件配置。\n配置节点失效后的pod重新调度最长等待时间\n容忍程度也可以配置，当某个 Pod 所在节点 NotReady 或者 Unreachable 是， k8s 可以等待该 Pod 重新调度之前的最长等待时间。\n... tolerations: - effect: NoExecute key: node.alpha.kubernetes.io/notReady operator: Exists tolerationSeconds: 300 - effect: NoExecute key: node.alpha.kubernetes.io/unreachable operator: Exists tolerationSeconds: 300 ... 上面2个容忍表示，该 Pod 容忍所在节点处于 notReady 和 unreachable 状态维持 300s。超时后，再重新调度。\n2. 使用节点亲和将pod调度到指定节点 #  污点可以拒绝调度，亲和允许调度。早期的 k8s 版本，节点亲和，就是 Pod 中的 nodeSelector 字段。 与节点选择器类似，每个节点都可以配置亲和性规则，可以是硬性标注，也可以是偏好。\n检查节点默认标签\nkubectl describe node gke-kubia-default-adj12knzf-2dascjb Name: gke-kubia-default-adj12knzf-2dascjb Role: Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux failure-domain.beta.kubernetes.io/region=europe-west1 failure-domain.beta.kubernetes.io/zone=europe-west1-d kubernetes.io/hostname=gke-kubia-default-adj12knzf-2dascjb 这是一个 gke 的节点，最后三个标签涉及到亲和性，分别表示所在地理地域，可用性区域，和主机名。\n2.1 指定强制节点亲和性规则 #  下面展示了只能被部署到含有 gpu=true 标签的节点上的 Pod：\napiVersion: v1 kind: Pod metadata: name: kubia-gpu spec: affinity: nodeAffinity: requiredDuringSchdulingIgnoredDuringExecution: lableSelectorTerms: - matchExpressions: - key: gpu operator: In values: - \u0026#34;true\u0026#34; 较长的节点亲和性属性名的含义\n requireDuringScheduling\u0026hellip;表示该字段下定义的规则，为了让 Pod 调度到该节点上，必须满足的标签。 \u0026hellip;IgnoredDuringExecution 表明该字段下的规则，不会影响已经在节点上的 Pod。  了解节点选择器的条件\nlableSelectorTerms 和 matchExpressions 定义了节点的标签必须满足哪一种表达方式。\n2.2 调度pod时优先考虑某些节点 #  节点亲和性和节点选择器相比，最大的好处就是， 当调度某一个 Pod，指定可以优先考某些节点，如果节点均无法满足，调度结果也是可以接受的。 这是由 preferdDuringSchdulingIgnoredDuringExecution 字段实现的。\n添加标签\nkubectl label node node1.k8s availability-zone=zone1 kubectl label node node1.k8s share-type=dedicated kubectl label node node2.k8s availability-zone=zone2 kubectl label node node2.k8s share-type=shared 指定优先级节点亲和性\napiVersion: apps/v1 kind: Deployment metadata: name: pref spec: template: ... spec: affinity: nodeAffinity: prefereddDuringSchdulingIgnoredDuringExecution: - weight: 80 preference: - matchExpressions: - key: availability-zone operator: In values: - zone1 - weight: 20 preference: - matchExpressions: - key: share-type operator: In values: - dedicated 上面描述一个节点亲和优先级，并不是强制要求。想要 Pod 调度到含有 availability-zone=zone1 和 share-type=dedicated 的节点上。第一个优先级相对重要，weight=80，第二个相对不重要，weight=20。\n了解优先级是如何工作的\n如果集群中包含很多节点，上面的 deployment，将会把节点分成四种。2 个标签都包含的，优秀级最高； 只包含 weight=80 的标签节点次之；然后只是包含 weight=20 的节点；剩下的节点排在最后。\n在一个包含 2 个节点的集群中部署\n如果在只有 node1 和 node2 的集群中部署一个 replica=5 的 Deployment，Pod 更多部署到 node1， 有极少数调度到 node2 上。这是因为 kube-schduler 除了节点亲和的优先级函数， 还有其他函数来决定 Pod 调度到哪里。其中之一就是 Selector SpreadPriority 函数， 此函数保证同一个 ReplicaSet 或者 Service 的 Pod，将分散到不同节点上。 避免单个节点失效而出现整个服务挂掉。\n3. 使用pod亲和和反亲和部署 Pod #  刚才描述了 Pod 和节点之间的亲和关系，也有 Pod 与 Pod 之间的亲和关系， 例如前端 Pod 和后端 Pod，尽可能部署较近，减少网络时延。\n3.1 使用 Pod 亲和将多个 Pod 部署到同一个节点上 #  部署 1 个后端 Pod 和 5 个前端 Pod。先部署后端：\nkubectl run backend -l app=backend --image busybox --sleep 9999 这里没什么区别，只是给 Pod 加了个标签，app=backend。\n在 Pod 中指定亲和性\napiVersion: apps/v1 kind: Deployment metadata: name: frontend spec: replicas: 5 template: ... spec: affinity: podAffinity: requireddDuringSchdulingIgnoredDuringExecution: - topologyKey: kubernetes.io/hostname labelSelector: matchLabels: app: backend 这里强制要求，frontend 的 Pod 被调度到和其他包含 app=backend 标签的 Pod 所在的相同节点上。 这是通过 topologyKey 指定的。\n了解调度器如何使用pod亲和规则\n上面的应用部署后，5 个前端 Pod 和 1 个后端 Pod 都在 node2 上。 假设后端 Pod 被误删，重新调度后，依旧在 node2 上。 虽然后端 Pod 本身没有定义任何亲和性规则，如果调度到其他节点，即会打破已有的亲和规则。\n3.2 将pod部署到同一个机柜、可用性区域或者地理地域 #  同一个可用性区域协调部署\n如果想要 Pod 在同一个 available zone 部署应用， 可以将 topologyKey 设置成 failure-domain.beta.kubernetes.io/zone。\n同一个地域协调部署 如果想要 Pod 在同一个 available zone 部署应用， 可以将 topologyKey 设置成 failure-domain.beta.kubernetes.io/region。\n了解 topologyKey 如何工作 topologyKey 的工作方式很简单，上面提到的三个属性并没有什么特别。可以设置成任意你想要的值。\n当调度器决定决定 Pod 调度到哪里时，首先检查 podAffinity 配置，选择满足条件的 pod， 接着查询这些 Pod 运行在那些节点上。特别寻找能匹配 podAffinity 配置的 topologyKey 的节点。 接着，会优先选择所有标签匹配的 Pod 的值的节点。\n3.3 pod优先级亲和性 #  与节点亲和一样，pod 之间也可以用 prefereddDuringSchdulingIgnoredDuringExecution。\napiVersion: apps/v1 kind: Deployment metadata: name: frontend spec: replicas: 5 template: ... spec: affinity: podAffinity: prefereddDuringSchdulingIgnoredDuringExecution: - weight: 80 podAffinityTerm: topologyKey: kubernetes.io/hostname labelSelector: matchLabels: app: backend 和 nodeAffinity 一样，设置了权重。也需要设置 topologyKey 和 labelSelector。\n3.4 pod反亲和分开调度pod #  同理，有 nodeAntiAffinity，也有 podAntiAffinity。 这将导致调度器永远不会选择包含 podAntiAffinity 的 Pod 所在的节点。\n使用反亲和分散pod\napiVersion: apps/v1 kind: Deployment metadata: name: frontend spec: replicas: 5 template: metadata: labels: app: frontend spec: affinity: podAffinity: requiredDuringSchdulingIgnoredDuringExecution: topologyKey: kubernetes.io/hostname labelSelector: matchLabels: app: frontend 上面的 Deployment 创建后，5 个实例应当分布在 5 个不同节点上。\n理解 Pod 反亲和优先级\n在这种情况下，可能使用软反亲和策略（prefereddDuringSchdulingIgnoredDuringExecution）。 毕竟 2 个前端 Pod 在同一个节点上也不是什么问题。如果运行在一个节点上出现问题， 那么使用 requiredDuringSchdulingIgnoredDuringExecution 就比较合适了。 与 Pod 亲和一样，topologyKey 决定了 Pod 不能被调度的范围。\n"});index.add({'id':4,'href':'/docs/kubernetes/sig-network/learn-about-Service/','title':"深入了解 Service",'section':"sig-network",'content':"一、基本概念 #  1.1 Service 定义详解 #  Service 是对一组提供相同功能的 Pods 的抽象，并为它们提供一个统一的入口。借助 Service， 应用可以方便的实现服务发现与负载均衡，并实现应用的零宕机升级。Service 通过标签来选取服务后端， 一般配合 Replication Controller 或者 Deployment 来保证后端容器的正常运行。 这些匹配标签的 Pod IP 和端口列表组成 endpoints， 由 kube-proxy 负责将服务 IP 负载均衡到这些 endpoints 上。\napiVersion: v1 kind: Service metadata: name: string namespace: string labels: - name: string annotations: - name: string spec: selector: [] # ClusterIP、NodePort、LoadBalancer type: string # type=ClusterIP, 有自动分配的能力；type=LoadBalancer，需指定  clusterIP: string  # 是否支持session，默认为空，可选值ClutserIP，同一个client的request，都发送到同一个后端Pod  sessionAffinity: string  ports: - name: string # tcp、udp，默认tcp protocol: string  port: int targetPort: int nodePort: int # spec.type=LoadBalancer,设置外部负载均衡器地址，用于公有云环境 status: loadBalancer: ingress: ip: string hostname: string 1.2 Service 分类 #   ClusterIP：默认类型，自动分配一个仅 cluster 内部可以访问的虚拟 IP NodePort：在 ClusterIP 基础上为 Service 在每台机器上绑定一个端口， 这样就可以通过 http://\u0026lt;NodeIP\u0026gt;:NodePort 来访问该服务。 如果 kube-proxy 设置了 --nodeport-addresses=10.240.0.0/16（v1.10 支持）， 那么仅该 NodePort 仅对设置在范围内的 IP 有效。 LoadBalancer：在 NodePort 的基础上，借助 cloud provider 创建一个外部的负载均衡器， 并将请求转发到 \u0026lt;NodeIP\u0026gt;:NodePort ExternalName：将服务通过 DNS CNAME 记录方式转发到指定的域名（通过 spec.externlName 设定）。 需要 kube-dns 版本在 1.7 以上。  二、Service 基本用法 #  一般来说，对外提供服务的应用程序需要通过某种机制来实现， 对于容器应用最简便的方式就是通过 TCP/IP 机制及监听IP和端口号来实现。\n直接通过Pod的IP地址和端口号可以访问到容器应用内的服务，但是 Pod 的 IP 地址是不可靠的， 例如当Pod所在的Node发生故障时，Pod 将被 Kubernetes 重新调度到另一个 Node， Pod 的 IP 地址将发生变化。 更重要的是，如果容器应用本身是分布式的部署方式，通过多个实例共同提供服务， 就需要在这些实例的前端设置一个负载均衡器来实现请求的分发。 Kubernetes中的Service就是用于解决这些问题的核心组件。\nService 定义中的关键字段是 ports 和 selector。通过 selector 与 Pod 关联， port 描述 service 本身的端口，targetPort 表示流量转发的端口，也就是 Pod 的端口， 从而完成访问 service 负载均衡到后端任意一个 Pod。Kubernetes提供了两种负载分发策略： RoundRobin 和 SessionAffinity，具体说明如下：\n RoundRobin：轮询模式，即轮询将请求转发到后端的各个 Pod 上。 SessionAffinity：基于客户端IP地址进行会话保持的模式， 即第 1 次将某个客户端发起的请求转发到后端的某个 Pod 上， 之后从相同的客户端发起的请求都将被转发到后端相同的 Pod 上。  在默认情况下，Kubernetes 采用 RoundRobin 模式对客户端请求进行负载分发， 但我们也可以通过设置 service.spec.sessionAffinity=ClientIP 来启用 SessionAffinity 策略。 这样，同一个客户端IP发来的请求就会被转发到后端固定的某个Pod上了。\n2.1 集群内访问集群外服务 #  到现在为止，我们己经讨论了后端是集群中运行的一个或多个 Pod 的服务。 但也存在希望通过 Kubernetes 服务特性暴露外部服务的情况。 不要让服务将连接重定向到集群中的Pod，而是让它重定向到外部 IP 和端口。 这样做可以让你充分利用服务负载平衡和服务发现。 在集群中运行的客户端 Pod 可以像连接到内部服务一样连接到外部服务。\n首先要知道，service 和 Pod 并不是直接相连的，此二者之间还有一个对象叫 endpoint。 service 根据 selector 找到后端 Pod，用 Pod IP 和端口创建与 service 同名的 endpoint， 记录 Pod IP。当 Pod 异常被删除重建后，获得的新地址，只需要更新 endpoint 中记录的 Pod I P即可。 因此，想要访问集群外部的服务，可手动配置 service 的 endpoint。\n2.1.1 创建没有 selector 的 Service #   创建没有 selector 的 Service  apiVersion: v1 kind: Service metadata: name: external-service spec: ports: - port: 80 为没有选择器的服务创建 Endpoint 资源  apiVersion: v1 kind: Endpoint metadata: # endpoint的名称必须和服务的名称相匹配 name: external-service  subsets: - addresses: # 将service重定向到endpoint的地址 - ip: 11.11.11.11 - ip: 22.22.22.22 ports: # endpoint目标端口 - port: 80 Endpoint 对象需要与服务具有相同的名称，并包含该服务的目标 IP 地址和端口列表。 服务和 Endpoint 资源都发布到服务器后，这样服务就可以像具有 Pod 选择器那样的服务正常使用。 在服务创建后创建的容器将包含服务的环境变量，并且与其 IP:Port 对的所有连接都将在服务端点之间进行负载均衡。\n2.1.2 创建 ExternalName的service #  除了手动配置服务的 Endpoint 来代替公开外部服务方法，有一种更简单的方法， 就是通过其完全限定域名(FQDN)访问外部服务。\n要创建一个具有别名的外部服务的服务时，要将创建服务资源的一个 type 字段设置为 ExternalName。 例如，设想一下在 api.somecompany.com 上有公共可用的 API 可以定义一个指向它的服务， 如下面的代码清单所示：\napiVersion: v1 kind: Service metadata: name: external-service spec: type: ExternalName externalName: someapi.somecompany.com ports: - port: 80 服务创建完成后，Pod 可以通过 external-service.default.svc.cluster.local 域名 (甚至是 external-service)连接到外部服务，而不是使用服务的实际 FQDN。 这隐藏了实际的服务名称及其使用该服务的 Pod 的位置，允许修改服务定义， 并且在以后如果将其指向不同的服务，只需简单地修改 externalName 属性， 或者将类型重新变回 Cluster IP并为服务创建 Endpoint ——无论是手动创建， 还是对服务上指定标签选择器使其自动创建。\nExternalName 服务仅在DNS级别实施——为服务创建了简单的 CNAME DNS 记录。 因此，连接到服务的客户端将直接连接到外部服务，完全绕过服务代理。 出于这个原因，这些类型的服务甚至不会获得集群IP。\n2.2 集群外访问集群内服务 #  2.2.1 NodePort服务 #  将服务的类型设置成 NodePort：每个集群节点都会在节点上打开一个端口，对于 NodePort 服务， 每个集群节点在节点本身(因此得名叫 NodePort)上打开一个端口， 并将在该端口上接收到的流量重定向到基础服务。该服务仅在内部集群 IP 和端口上才可访间， 但也可通过所有节点上的专用端口访问。\napiVersion: v1 kind: Service metadata: name: kubia-nodeport spec: type: NodePort ports: - port: 80 targetPort: 8080 nodePort: 30123 selector: app: kubia 2.2.2 LoadBalancer 服务 #  在云提供商上运行的 Kubernetes 集群通常支持从云基础架构自动提供负载平衡器。 所有需要做的就是设置服务的类型为 LoadBadancer 而不是 NodePort。 负载均衡器拥有自己独一无二的可公开访问的IP地址，并将所有连接重定向到服务。 可以通过负载均衡器的 IP 地址访问服务。\n如果 Kubemetes 在不支持 LoadBadancer 服务的环境中运行，则不会调配负载平衡器， 但该服务仍将表现得像一个 NodePort 服务。这是因为 LoadBadancer 服务是 NodePort 服务的扩展。\napiVersion: v1 kind: Service metadata: name: kubia-loadbalancer spec: type: LoadBalancer ports: - port: 80 targetPort: 8080 selector: app: kubia clusterIP: 10.0.171.239 loadBalancerIP: 78.11.24.19 status: loadBalancer: ingress: - ip: 146.148.47.155 三、通过 Ingress 暴露服务 #   为什么需要 Ingress？  一个重要的原因是每个 LoadBalancer 服务都需要自己的负载均衡器，以及独有的公有 IP 地址， 而 Ingress 只需要一个公网 IP 就能为许多服务提供访问。当客户端向 Ingress 发送 HTTP 请求时， Ingress 会根据请求的主机名和路径决定请求转发到的服务。\n3.1 创建 Ingress Controller 和默认的 backend 服务 #  在定义 Ingress 策略之前，需要先部署 Ingress Controller， 以实现为所有后端 Service 都提供一个统一的入口。 Ingress Controller 需要实现基于不同 HTTP URL 向后转发的负载分发规则， 并可以灵活设置 7 层负载分发策略。如果公有云服务商能够提供该类型的 HTTP 路由 LoadBalancer， 则也可设置其为 Ingress Controller。\n在 Kubernetes 中，Ingress Controller 将以 Pod 的形式运行， 监控 API Server 的 ingress 接口后端的 backend services， 如果 Service 发生变化，则 Ingress Controller 应自动更新其转发规则。\n下面的例子使用Nginx来实现一个 Ingress Controller，需要实现的基本逻辑如下：\n 监听 API Server，获取全部 Ingress 的定义。 基于 Ingress 的定义，生成 Nginx 所需的配置文件 /etc/nginx/nginx.conf。 执行 nginx -s reload 命令，重新加载 nginx.conf 配置文件的内容。  为了让 Ingress Controller 正常启动，还需要为它配置一个默认的 backend， 用于在客户端访问的 URL 地址不存在时，返回一个正确的 404 应答。 这个 backend 服务用任何应用实现都可以，只要满足对根路径“/”的访问返回 404 应答， 并且提供 /healthz 路径以使 kubelet 完成对它的健康检查。 另外，由于 Nginx 通过 default-backend-service 的服务名称（Service Name）去访问它， 所以需要 DNS 服务正确运行。\n3.2 创建 ingress 资源 #  3.2.1 转发到单个后端服务上 #  基于这种设置，客户端到 Ingress Controller 的访问请求都将被转发到后端的唯一 Service 上， 在这种情况下 Ingress 无须定义任何 rule。\n通过如下所示的设置，对 Ingress Controller 的访问请求都将被转发到“myweb:8080”这个服务上。\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test-ingress spec: backend: serviceName: webapp servicePort: 8080 3.2.2 将不同的服务映射到相同主机的不同路径 #  这种配置常用于一个网站通过不同的路径提供不同的服务的场景， 例如 /web 表示访问 Web 页面，/api表示访问 API 接口，对应到后端的两个服务， 通过Ingress的设置很容易就能将基于 URL 路径的转发规则定义出来。\n通过如下所示的设置，对 mywebsite.com/web 的访问请求将被转发到 web-service:80 服务上； 对 mywebsite.com/api 的访问请求将被转发到 api-service:80 服务上：\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test-ingress spec rules: - host mywebsite.com http: paths: - path: /web backend: serviceName: web-service servicePort: 80 - path: /api backend: serviceName: api-service servicePort: 80 3.2.3 不同的域名(虚拟主机名)被转发到不同的服务上 #  这种配置常用于一个网站通过不同的域名或虚拟主机名提供不同服务的场景， 例如 foo.example.com 域名由 foo 提供服务，bar.example.com 域名由 bar 提供服务。\n通过如下所示的设置，对“foo.example.com”的访问请求将被转发到“foo:80”服务上， 对“bar.example.com”的访问请求将被转发到“bar:80”服务上：\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test-ingress spec: rules: - host: foo.example.com http: paths: - path: I backend: serviceName: foo servicePort: 80 - host: bar.example.com http: paths: - path: I backend: serviceName: bar servicePort: 80 3.2.4 不使用域名的转发规则 #  这种配置用于一个网站不使用域名直接提供服务的场景， 此时通过任意一台运行 ingress-controller 的 Node 都能访问到后端的服务。\n下面的配置为将“/demo”的访问请求转发到“webapp:8080/demo”服务上：\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test-ingress spec: rules: - http: paths: - path: /demo backend: serviceName: webapp servicePort: 8080 注意，使用无域名的 Ingress 转发规则时，将默认禁用非安全 HTTP，强制启用 HTTPS。 可以在 Ingress 的定义中设置一个 annotation[ingress.kubernetes.io/ssl-redirect: \u0026ldquo;false\u0026rdquo;] 来关闭强制启用 HTTPS 的设置：\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test-ingress annotations: ingress.kubernetes.io/ssl-redirect: \u0026#34;false\u0026#34; spec: rules: - http: paths: - path: /demo backend: serviceName: webapp servicePort: 8080 3.3 Ingress 的 TLS 安全设置 #  当客户端创建到 Ingress 控制器的 TLS 连接时，控制器将终止 TLS 连接。 客户端和控制器之间的通信是加密的，而控制器和后端 Pod 之间的通信则不是运行在 Pod 上的应用程序不需要支持 TLS。 例如，如果 Pod 运行 web 服务器，则它只能接收 HTTP 通信，并让 Ingress 控制器负责处理与 TLS 相关的所有内容。 要使控制器能够这样做，需要将证书和私钥附加到 Ingress。 这两个必需资源存储在称为 Secret 的 Kubernetes 资源中，然后在 Ingress manifest 中引用它。\n为了 Ingress 提供 HTTPS 的安全访问，可以为 Ingress 中的域名进行 TLS 安全证书的设置。设置的步骤如下。\n 创建自签名的密钥和 SSL 证书文件  openssl genrsa -out tls.key 2048 openssl req -new - x509 -key tls.key -out tls.cert -days 360 -subject/CN=kubia.example.com 将证书保存到Kubernetes中的一个Secret资源对象上  kubectl create secret tls mywebsite-tls-secret --cert=tls.cert --key=tls.key 将该 Secret 对象设置到 Ingress 中  apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: mywebsite-ingress-tls spec: tls: - hosts: - mywebsite.com secretName: mywebsite-tls-secret rules: - http: paths: - path: /demo backend: serviceName: webapp servicePort: 8080 根据提供服务的网站域名是一个还是多个，可以使用不同的操作完成前两步 SSL 证书和 Secret 对象的创建， 在只有一个域名的情况下设置相对简单。第3步对于这两种场景来说是相同的。\n"});index.add({'id':5,'href':'/docs/kubernetes/sig-node/kubelet-eviction-manager/','title':"kubelet eviction manager",'section':"sig-node",'content':"1、概述 #  在可用计算资源较少时，kubelet 为保证节点稳定性，会主动地结束一个或多个 pod 以回收短缺地资源， 这在处理内存和磁盘这种不可压缩资源时，驱逐 pod 回收资源的策略，显得尤为重要。 下面来具体研究下 Kubelet Eviction Policy 的工作机制。\n kubelet 预先监控本节点的资源使用，防止资源被耗尽，保证节点稳定性。 kubelet 会预先 Fail N(\u0026gt;=1)个Pod，以回收出现紧缺的资源。 kubelet 在 Fail一个 pod 时，kill掉pod内所有 container，并设置 pod.status.phase = Failed。 kubelet 按照事先设定好的 Eviction Threshold 来触发驱逐动作，实现资源回收。  1.1 驱逐信号 #  在源码 pkg/kubelet/eviction/api/types.go 中定义了以下及几种 Eviction Signals：\n   Eviction Signal Description     memory.available := node.status.capacity[memory] - node.stats.memory.workingSet   nodefs.available := node.stats.fs.available   nodefs.inodesFree := node.stats.fs.inodesFree   imagefs.available := node.stats.runtime.imagefs.available   imagefs.inodesFree := node.stats.runtime.imagefs.inodesFree   allocatableMemory.available := pod.allocatable - pod.workingSet   pid.available := node.MaxPID - node.NumOfRunningProcesses    上表主要涉及三个方面，memory、file system 和 pid。其中 kubelet 值支持 2 种文件系统分区：\n nodefs：kubelet 用来存储 volume 和 daemon logs 等 imagesfs：容器运行时( docker 等)用来保存镜像和容器的 writable layer  1.2 驱逐阈值 #  kubelet 的入参接收用户定义的 eviction signal 和 eviction threshold 的映射关系，格式如下：\n[eviction-signal] [opterator] [quantity]\n 支持的 signal 如上表所示； operator 是关系运算符，例如\u0026lt;； quantity 是驱逐阈值，合法的值必须是 kubernetes 使用的数量表示，例如 1Gi 和 10% 等；  1.2.1 软驱逐策略 #  Soft Eviction Thresholds，它与以下三个参数配合使用：\n eviction-soft：(e.g. memory.available\u0026lt;1.5Gi) 触发软驱逐的阈值； eviction-soft-grace-period：(e.g. memory.available=1m30s) 当达到软驱逐的阈值，需要等待的时间； 在这段时间内，每 10s 会重新获取监控数据并更新 threshold 值， 如果在等待期间，最后一次的数据仍然超过阈值，才会触发驱逐 pod 的行为。 eviction-max-pod-grace-period：(e.g. 30s) 当满足软驱逐阈值并终止 pod 时允许的最大宽限期值。 如果待 Evict 的 Pod 指定了pod.Spec.TerminationGracePeriodSeconds， 则取min(eviction-max-pod-grace-period, pod.Spec.TerminationGracePeriodSeconds) 作为 Pod Termination 真正的 Grace Period。  因此，在软驱逐策略下，从 kubelet 检测到驱逐信号达到了阈值设定开始，到 pod 真正被 kill掉， 共花费的时间是：sum(eviction-max-pod-grace-period, min(eviction-max-pod-grace-period, pod.Spec.TerminationGracePeriodSeconds))\n1.2.2 硬驱逐 #  Hard Eviction Thresholds 比 Soft Eviction Thresholds 简单粗暴，没有宽限期， 即使 pod 配置了 pod.Spec.TerminationGracePeriodSeconds，一旦达到阈值配置， kubelet 立马回收关联的短缺资源，并且使用的就立即结束，而不是优雅终止。 此特性已经标记为 Deprecated。\n源码 pkg/kubelet/apis/config/v1beta1/defaults_linux.go 给出了默认的硬驱逐配置：\n memory.available \u0026lt; 100Mi nodefs.available \u0026lt; 10% nodefs.inodesFree \u0026lt; 5% imagefs.available \u0026lt; 15%  1.3 驱逐周期 #  有了驱逐信号和阈值，也有了策略，接下来就是 Eviction Monitoring Interval。 kubelet对应的监控周期，就通过 cAdvisor 的 housekeeping-interval 配置的，默认 10s。\n1.4 节点状态 #  kubelet 监测到配置的驱逐策略被触发，会将驱逐信号映射到对应的节点状态。 Kubelet 会将对应的 Eviction Signals 映射到对应的 Node Conditions， 源码[pkg/kubelet/eviction/helpers.go]，其映射关系如下：\n   节点状态 驱逐信号 描述     MemoryPressure memory.avaliable, allocatableMemory.available 节点或pod的可用内存触发驱逐阈值   DiskPressure nodefs.avaliable, nodefs.inodesFree, imagefs.available, imagesfs.inodesFree 节点的 root fs 或i mage fs 上的可用磁盘空间和索引节点已满足收回阈值   PIDPressure pid.available 节点的可用 PID 触发驱逐阈值    kubelet 映射了 Node Condition之 后，会继续按照--node-status-update-frequency(default 10s)配置的时间间隔， 周期性的与 kube-apiserver 进行 node status updates。\n1.5 节点状态振荡 #  ​考虑这样一种场景，节点上监控到 soft eviction signal 的值，始终在 eviction threshold 上下波动， 那么 kubelet 就会将该 node 对应的 node condition 在 true 和 false 之间来回切换。 给 kube-scheduler 产生错误的调度结果。\n​因此，kubelet 添加参数 eviction-pressure-transition-period (default 5m0s)配置， 使 Kubelet 在解除由 Evicion Signal 映射的 Node Pressure之前，必须等待 5 分钟。\n​驱逐逻辑添加了一步：\n Soft Evction Singal 高于 Soft Eviction Thresholds 时， Kubelet 还是会立刻设置对应的 MemoryPressure 或 DiskPressure 为 True。 当 MemoryPressure 或 DiskPressure为True 的前提下， 发生了 Soft Evction Singal 低于 Soft Eviction Thresholds 的情况， 则需要等待 eviction-pressure-transition-period(default 5m0s)配置的这么长时间， 才会将 condition pressure 切换回 False。  一句话总结：Node Condition Pressure成为True容易，切换回False则要等eviction-pressure-transition-period。\n1.6 回收节点层级资源 #  如果满足驱逐阈值并超过了宽限期，kubelet 将启动回收压力资源的过程， 直到它发现低于设定阈值的信号为止。 kubelet将尝试在驱逐终端用户 pod 前回收节点层级资源。 发现磁盘压力时，如果节点针对容器运行时配置有独占的 imagefs， kubelet 回收节点层级资源的方式将会不同。\n1.6.1 使用 imagefs #   如果 nodefs 文件系统满足驱逐阈值，kubelet 通过驱逐 pod 及其容器来释放磁盘空间。 如果 imagefs 文件系统满足驱逐阈值，kubelet 通过删除所有未使用的镜像来释放磁盘空间。  1.6.2 未使用 imagefs #   删除停止运行的 pod/container 删除全部没有被使用的镜像  1.7 驱逐策略 #  ​kubelet 根据 Pod 的 QoS Class 实现了一套默认的 Evication 策略， kubelet 首先根据他们对短缺资源的使用是否超过请求来排除 pod 的驱逐行为， 然后通过优先级，然后通过相对于 pod 的调度请求消耗急需的计算资源。图解如下：\n ​对于每一种 Resource 都可以将容器分为 3 种 QoS Classes: Guaranteed, Burstable 和 Best-Effort， 它们的 QoS 级别依次递减。\n BestEffort，按照短缺资源占用量排序，占用量越高，被 kill 的优先级越高； Burstable，对使用量高于请求量的 pod 排序，占用越多，回收优先级越高； 如果没有 pod 的使用超过请求，按照 BestEffort 策略回收； Guaranteed，Guaranteed pod 只有为所有的容器指定了要求和限制并且它们相等时才能得到保证。 由于另一个 pod 的资源消耗，这些 pod 保证永远不会被驱逐。 如果系统守护进程（例如 kubelet、docker、和 journald） 消耗的资源多于通过 system-reserved 或 kube-reserved 分配保留的资源， 并且该节点只有 Guaranteed 或 Burstable pod 使用少于剩余的请求， 然后节点必须选择驱逐这样的 pod 以保持节点的稳定性并限制意外消耗对其他 pod 的影响。 在这种情况下，它将首先驱逐优先级最低的 pod。  1.8 最小驱逐回收 #  有些情况下，可能只回收一小部分的资源就能使得 Evication Signal 的值低于 eviction thresholds。 但是，可能随着资源使用的波动或者新的调度 Pod 使得在该 Node 上很快又会触发 evict pods 的动作， eviction 毕竟是耗时的动作，所以应该尽量避免这种情况的发生。\n为了减少这类问题，每次 Evict Pods 后，Node 上对应的 Resource 不仅要比 Eviction Thresholds 低， 还要保证最少比 Eviction Thresholds，再低 --eviction-minimum-reclaim 中配置的数量。\n例如使用下面的配置：\n--eviction-hard=memory.available\u0026lt;500Mi,nodefs.available\u0026lt;1Gi,imagefs.available\u0026lt;100Gi --eviction-minimum-reclaim=\u0026#34;memory.available=0Mi,nodefs.available=500Mi,imagefs.available=2Gi\u0026#34; 如果 memory.available 驱逐阈值被触发，kubelet将保证 memory.available 至少为 500Mi。 对于 nodefs.available，kubelet将保证 nodefs.available 至少为 1.5Gi。 对于 imagefs.available，kubelet将保证 imagefs.available 至少为 102Gi， 直到不再有相关资源报告压力为止。\n所有资源的默认 eviction-minimum-reclaim 值为 0。\n"});index.add({'id':6,'href':'/menu/','title':"Menu",'section':"介绍",'content':"  kubernetes   SIG-API-Machinery  SIG-Apps  SIG-Scheduling  SIG-Node  SIG-Network    "});})();