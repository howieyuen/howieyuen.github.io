<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>介绍 on 袁昊的学习笔记</title>
    <link>https://howieyuen.github.io/</link>
    <description>Recent content in 介绍 on 袁昊的学习笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <atom:link href="https://howieyuen.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>概述</title>
      <link>https://howieyuen.github.io/docs/translation/protobuf/overview-of-protocal-buffers/</link>
      <pubDate>Thu, 05 May 2022 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/translation/protobuf/overview-of-protocal-buffers/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;原文链接：&#xA;  &lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/overview&#34;&gt;Overview | Protocol Buffers | Google Developers&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;协议缓冲区（Protocol Buffers，protobuf）提供了一种语言中立、平台中立、可扩展的机制，用来序列化结构化数据，并且支持向前/向后兼容。&#xA;它类似于 JSON，只是它更小更快，并且能生成本地语言绑定。&lt;/p&gt;&#xA;&lt;p&gt;protobuf 包含以下模块：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;定义语言（在 &lt;code&gt;.proto&lt;/code&gt; 文件中创建）&lt;/li&gt;&#xA;&lt;li&gt;连接数据的代码（ proto 编译器生成）&lt;/li&gt;&#xA;&lt;li&gt;特定语言的运行时库&lt;/li&gt;&#xA;&lt;li&gt;序列化格式的数据（写入文件或者通过网络传输）&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>语言指南（proto3）</title>
      <link>https://howieyuen.github.io/docs/translation/protobuf/language-guideproto3/</link>
      <pubDate>Tue, 10 May 2022 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/translation/protobuf/language-guideproto3/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;原文链接：&#xA;  &lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/proto3&#34;&gt;Language Guide(proto3) | Protocol Buffers | Google Developers&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;!-- &#xA;This guide describes how to use the protocol buffer language to structure your protocol buffer data, including .proto file syntax and how to generate data access classes from your .proto files. It covers the proto3 version of the protocol buffers language: for information on the proto2 syntax, see the Proto2 Language Guide.&#xA;&#xA;This is a reference guide – for a step by step example that uses many of the features described in this document, see the tutorial for your chosen language (currently proto2 only; more proto3 documentation is coming soon).&#xA;--&gt;&#xA;&lt;p&gt;本指南描述了如何使用 protobuf 语言结构化你的协议缓冲区数据，&#xA;包括 &lt;code&gt;.proto&lt;/code&gt; 文件语法和如何从你的 &lt;code&gt;.proto&lt;/code&gt; 文件生成数据访问的类（Class）。&#xA;它覆盖了 protobuf 语言的 &lt;strong&gt;proto3&lt;/strong&gt; 版本：对于 &lt;strong&gt;proto2&lt;/strong&gt; 语言的信息，&#xA;请查阅 &#xA;  &lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/proto&#34;&gt;Proto2 Language Guide&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;这是一篇参考指南——有关使用本文档中描述的许多功能的分步示例，&#xA;请参阅你选择的语言的&#xA;&#xA;  &lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/tutorials&#34;&gt;教程&lt;/a&gt;（目前仅有 proto2；更多 proto3 文档即将推出）。&lt;/p&gt;</description>
    </item>
    <item>
      <title>MonoRepo</title>
      <link>https://howieyuen.github.io/docs/getting-started/monorepo/</link>
      <pubDate>Thu, 18 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/getting-started/monorepo/</guid>
      <description>&lt;p&gt;MonoRepo，即单一代码库（Monolithic Repository），是将多个项目或组件的代码存储在同一个版本控制系统仓库中的一种源代码管理策略。大公司如 Google、Facebook、Twitter 等都采用了 MonoRepo 来管理他们庞大的代码库。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Helm Secrets</title>
      <link>https://howieyuen.github.io/docs/XaC/secret-as-code/helm-secrets/</link>
      <pubDate>Wed, 27 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/XaC/secret-as-code/helm-secrets/</guid>
      <description>概述 # Helm Secrets 是 Helm 的一个插件，能够利用 Helm 模板化 Secrets 资源。它使用 SOPS（Mozilla 研发）来加密 Secret。SOPS 是一个加密文件的编辑器，采用的是非对称加密，支持 YAML、JSON、ENV、INI 和二进制格式，并支持 AWS KMS、GCP KMS、Azure Key Vault 和 PGP 进行加密。&#xA;Helm Secrets 还支持其他后端，例如：vals，它是一种用于管理来自各种来源的配置值和秘密的工具。目前已经支持：&#xA;Vault AWS SSM Parameter Store AWS Secrets Manager AWS S3 GCP Secrets Manager Azure Key Vault SOPS-encrypted files Terraform State Plain File 下文以 PGP 方式为例，进行说明。&#xA;安装 # gpg:&#xA;brew install gpg sops:&#xA;brew install sops helm-secrets:&#xA;helm plugin install https://github.com/jkroepke/helm-secrets --version v3.</description>
    </item>
    <item>
      <title>Kamus</title>
      <link>https://howieyuen.github.io/docs/XaC/secret-as-code/kamus/</link>
      <pubDate>Wed, 27 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/XaC/secret-as-code/kamus/</guid>
      <description>概述 # Kamus 架构似于 Sealed Secrets 和 Helm Secrets。但是，Kamus 使你可以加密特定应用程序的 Secret，并且只有该应用程序可以解密。细化权限使 Kamus 更适合具有高安全标准的零信任环境。Kamus 通过关联 ServiceAccount 和你的 Secret 工作，仅有使用此服务帐户运行的应用程序对其进行解密。&#xA;Kamus 由三个模块组成：&#xA;加密 API 解密 API 密钥管理系统（KMS） 加密和解密 API 处理加密和解密请求。KMS 是各种加密解决方案的包装器。目前支持：&#xA;AES：对所有 Secret 使用一个密钥 AWS KMS、Azure KeyVault、Google Cloud KMS：为每个服务帐户创建一个密钥。 Kamus 附带 3 个实用程序，使其更易于使用：&#xA;CLI：一个小型 CLI，可简化与 Encrypt API 的交互。 init 容器：一个与 Decrypt API 交互的初始化容器。 CRD 控制器：允许使用 Kamus 创建本集群的 k8s Secret。 原理 # 加密 # 用户加密敏感信息（字符串，不是对象） kamus-cli 请求 kamus-encrytptor 加密 kamus-controller 提供公钥 加密结果返回 解密 # 用户下发 KamusSecret 类型的 CR，包含加密字段（kamus-secret.</description>
    </item>
    <item>
      <title>Google 在 MonoRepo 上的实践</title>
      <link>https://howieyuen.github.io/posts/google-on-monorepo/</link>
      <pubDate>Mon, 29 May 2023 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/posts/google-on-monorepo/</guid>
      <description>&lt;p&gt;Google 在早期就使用集中式源代码控制系统管理共享代码库。也就是说，在 Google 内部，是先有的 MonoRepo，然后基于 MonoRepo 形成了一套基于主干开发的工作流程，以及支撑此流程的工具。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Service 与 Endpoints、EndpointSlice 那些事</title>
      <link>https://howieyuen.github.io/docs/kubernetes/sig-network/svc-ep-epslice/</link>
      <pubDate>Tue, 31 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/sig-network/svc-ep-epslice/</guid>
      <description>Service 与 Endpoints、EndpointSlice 那些事 # Service 资源 # k8s Service 定义了这样一种抽象：逻辑上的一组 Pod，一种可以访问它们的策略 —— 通常称为微服务。 Service 所针对的 Pod 集合通常是通过 LabelSelector 来确定的。 LabelSelector 选中的 Pod，将会自动创建与 Service 同名且同 Namespace 的 Endpoint 对象，将 Pod 的 IP 写入其中。&#xA;如果没有 LabelSelector，用户可能是希望 Service 关联的后端是集群外的服务，或者是其他 Namespace； 如果用户还想要使用负载均衡服务，需要自行创建与 Service 同名的 Endpoints 对象。&#xA;Service 类型 # k8s Service 分为 4 种类型（svc.spec.type）：&#xA;ClusterIP：通过集群的内部 IP 暴露服务，选择该值时服务只能够在集群内部访问。 这也是默认的 ServiceType。 NodePort：通过每个节点上的 IP 和静态端口（NodePort）暴露服务。 NodePort 服务会路由到自动创建的 ClusterIP 服务。 通过请求 &amp;lt;node ip&amp;gt;:&amp;lt;node port&amp;gt;，你可以从集群的外部访问一个 NodePort 服务。 LoadBalance：使用云提供商的负载均衡器向外部暴露服务。 外部负载均衡器可以将流量路由到自动创建的 NodePort 服务和 ClusterIP 服务上。 ExternalName：通过返回 CNAME 和对应值，可以将服务映射到 externalName 字段的内容； 例如，foo.</description>
    </item>
    <item>
      <title>Acorn：k8s 应用部署框架</title>
      <link>https://howieyuen.github.io/docs/XaC/infra-as-code/getting-started-of-acorn/</link>
      <pubDate>Fri, 16 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/XaC/infra-as-code/getting-started-of-acorn/</guid>
      <description>概述 # Acorn 是一个应用程序打包和部署框架，可简化在 Kubernetes 上运行的应用程序。 Acorn 能够将应用程序的所有 Docker 镜像、配置和部署规范打包到单个 Acorn 镜像工件中。 此工件可发布到任何 OCI 容器注册表，允许它部署在任何开发、测试或生产环境的 Kubernetes 上。 Acorn 镜像的可移植性使开发人员能够在本地开发应用程序并转移到生产环境，而无需切换工具或技术堆栈。&#xA;开发人员通过在 Acornfile 中描述应用程序配置来创建 Acorn 镜像。 Acornfile 描述了整个应用程序，没有 Kubernetes YAML 文件的所有样板。 Acorn CLI 用于在任何 Kubernetes 集群上构建、部署和操作 Acorn 镜像。&#xA;架构 # acorn：安装在终端用户的机器上，并针对在 Kubernetes 集群中运行的 acorn-apiserver 交互 acorn-apiserver：k8s 风格的 API 服务器，通过 k8s aggregation layer 访问 acorn-controller：负责将 Acorn 应用程序转换为实际的 Kubernetes 资源 buildkit &amp;amp; internal registry：镜像构建服务、Buildkit 和内部镜像注册表作为同级容器部署在单个 pod 中。当 Buildkit 构建新的 Acorn 镜像时，这简化了两个组件之间的通信 工作流 # 下图说明了用户在使用 Acorn 时所采取的步骤：</description>
    </item>
    <item>
      <title>Terraform 执行状态和阶段关系</title>
      <link>https://howieyuen.github.io/docs/XaC/infra-as-code/terraform-workflow/</link>
      <pubDate>Fri, 16 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/XaC/infra-as-code/terraform-workflow/</guid>
      <description>&lt;p&gt;Terraform 每次运行都经过多个操作阶段（Pending、Plan、Cost Estimation、Policy Check、Apply 和 Completion），Terraform Cloud 将这些阶段的进度显示为运行状态。&#xA;在 Terraform Cloud 主页上的工作区列表中，每个工作区都显示了它当前正在处理的运行状态。（或者，如果没有正在进行的运行，则为最近完成的运行的状态。）&lt;/p&gt;</description>
    </item>
    <item>
      <title>令人愉悦的 CLI 的 10 条设计原则</title>
      <link>https://howieyuen.github.io/posts/10-design-principles-for-delightful-clis/</link>
      <pubDate>Mon, 21 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/posts/10-design-principles-for-delightful-clis/</guid>
      <description></description>
    </item>
    <item>
      <title>Secrets Store CSI Driver</title>
      <link>https://howieyuen.github.io/docs/XaC/secret-as-code/secrets-store-csi-driver/</link>
      <pubDate>Wed, 02 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/XaC/secret-as-code/secrets-store-csi-driver/</guid>
      <description>概述 # Secrets Store CSI Driver 通过 容器存储接口 (CSI) 卷将 Secret 存储与 Kubernetes 集成。&#xA;Secrets Store CSI Driver secrets-store.csi.k8s.io 允许 Kubernetes 将外部机密存储中的多个 Secret、密钥和证书作为卷挂载到其 Pod 中。 附加卷后，其中的数据将被挂载到容器的文件系统中。&#xA;Secrets Store CSI Driver 是一个 DaemonSet，可促进与每个 Kubelet 实例的通信。每个驱动程序 Pod 都有以下容器：&#xA;node-driver-registrar：负责向 Kubelet 注册 CSI 驱动程序，以便它知道在哪个 unix 域套接字上发出 CSI 调用。 此 sidecar 容器由 Kubernetes CSI 团队提供。 secrets-store：实现 CSI 规范中描述的 CSI 节点服务 gRPC 服务。 它负责在 Pod 创建/删除期间挂载/卸载卷。 此组件在 secrets-store-csi-driver 仓库中开发和维护。 liveness-probe：负责监控 CSI 驱动的健康状况并向 Kubernetes 报告。 这使 Kubernetes 能够自动检测驱动程序的问题并重新启动 Pod 以尝试修复问题。 此 sidecar 容器由 Kubernetes CSI 团队提供。 Provider # CSI Driver 使用 gRPC 与 Provider 通信，以从外部 Secrets Store 获取挂载内容。 有关如何为 Driver 实现 Provider 和支的持 Provider 的标准的更多详细信息，请参阅 Providers。</description>
    </item>
    <item>
      <title>Golang 中的 RSA 加解密算法</title>
      <link>https://howieyuen.github.io/posts/rsa-crypto-in-go/</link>
      <pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/posts/rsa-crypto-in-go/</guid>
      <description>&lt;p&gt;本文受到 Gitlab 中 &#xA;  &lt;a href=&#34;https://gitlab.com/rahasak-labs/crypgo&#34;&gt;&lt;code&gt;crypgo&lt;/code&gt;&lt;/a&gt; 项目启发，&#xA;作者在 Medium 中发表了一篇博文，&#xA;  &lt;a href=&#34;https://medium.com/rahasak/golang-rsa-cryptography-1f1897ada311&#34;&gt;RSA cryptography in Golang&lt;/a&gt; 作为说明。&#xA;读完后发现代码中存在一些小问题，因此重整代码实现，使其更加实用。&lt;/p&gt;</description>
    </item>
    <item>
      <title>DevOps vs GitOps</title>
      <link>https://howieyuen.github.io/posts/devops-vs-gitops/</link>
      <pubDate>Sat, 15 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/posts/devops-vs-gitops/</guid>
      <description>&lt;p&gt;GitOps 和 DevOps 正迅速成为开发团队的黄金标准方法。DevOps 文化代表了从传统软件和技术开发的转变，传统的软件和技术开发涉及从构思和概念到发布的线性路径，并鼓励协作和快速反馈，而不是孤立地工作。在本文中，我们将仔细研究 GitOps 与 DevOps，以帮助确定 GitOps 是否适用于您的软件开发项目。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sealed Secrets</title>
      <link>https://howieyuen.github.io/docs/XaC/secret-as-code/sealed-secrets/</link>
      <pubDate>Sat, 15 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/XaC/secret-as-code/sealed-secrets/</guid>
      <description>概述 # Sealed Secrets 由两个部分组成：&#xA;集群侧控制器：sealed-secrets-controller 用户侧工具：kubeseal kubeseal 使用非对称加密算法，加密 Secret，加密结果仅有 sealed-secrets-controller 才能解密。 加密后的 Secret 编码在 SealedSecret 资源中，详细结构如下：&#xA;apiVersion: bitnami.com/v1alpha1 kind: SealedSecret metadata: name: mysecret namespace: mynamespace spec: encryptedData: foo: AgBy3i4OJSWK+PiTySYZZA9rO43cGDEq..... 解密后的 Secret 如下：&#xA;apiVersion: v1 kind: Secret metadata: name: mysecret namespace: mynamespace data: foo: YmFy # &amp;lt;- base64 encoded &amp;#34;bar&amp;#34; SealedSecret 和 Secret 的关系类似于 Deployment 和 Pod，SealedSecret 有个 template 字段，是生成的 Secret 的模板； 此二者之间的 labels 和 annotations 并不要求完成一致。 最终生成的 Secret 与 SealedSecret 相对独立，但 SealedSecret 的更新或删除，会连带到生成的 Secret。</description>
    </item>
    <item>
      <title>如何管理 GitOps Secret：详细指南</title>
      <link>https://howieyuen.github.io/posts/how-to-manage-gitops-secrets-a-detailed-guide/</link>
      <pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/posts/how-to-manage-gitops-secrets-a-detailed-guide/</guid>
      <description>&lt;p&gt;GitOps 正变得越来越流行。越来越多的公司开始使用 Git 作为其基础设施和应用程序配置的真实来源。然而，伴随其优势而来的是挑战。例如，如果你的所有配置都存储在 Git 中，你如何管理 Secret？你不能简单地将密码和令牌以明文形式提交到 Git 存储库，即使该存储库是私有的并且只有少数人可以访问它。在这篇文章中，你将学习如何安全地管理 GitOps Secret。敬请关注。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Circle CI</title>
      <link>https://howieyuen.github.io/docs/getting-started/circle-ci/</link>
      <pubDate>Tue, 14 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/getting-started/circle-ci/</guid>
      <description>&lt;p&gt;CircleCI 是基于云的 CI/CD 工具，可自动执行软件构建和交付过程。它提供快速的配置和维护，没有任何复杂性。&#xA;由于它是基于云的 CI/CD 工具，因此消除了专用服务器的困扰，并降低了维护本地服务器的成本。&#xA;此外，基于云的服务器是可扩展的，健壮的，并有助于更快地部署应用程序。&lt;/p&gt;</description>
    </item>
    <item>
      <title>使用 Argo CD ApplicationSet 管理多集群</title>
      <link>https://howieyuen.github.io/docs/XaC/cicd/argocd/</link>
      <pubDate>Thu, 21 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/XaC/cicd/argocd/</guid>
      <description>本文翻译自 Manage More Clusters with Less Hassle, with Argo CD Application Sets - Jonathan and Kshama&#xA;ApplicationSet # Applicationset 是一种新的Kubernetes自定义资源（CR）和控制器，它与现有的 Argo CD 一起工作。 Applicationset 是 Argo CD 应用程序的工厂：ApplicationSet CR 描述了创建/管理的应用程序，Argo CD 负责部署它们。&#xA;特征：&#xA;将大量 Argo CD 应用程序作为单个单元管理 你集群的 Deployment 可以来自各种数据源的自动化和自定义： 例如，随着新的集群添加到基础架构中，添加了新的 Git Repo，将添加新的 Repo 到 Github/Gitlab 等 对外变更自动作出反应 基于外部事件的一致性是快速且可自定义的：在飞行中创建/更新/删除应用程序 Applicationset 基于 Argo CD 应用，可利用 Argo CD 带来的所有能力 GitOps 介绍 # Git 来源于事实 所需的软件状态在 Git 仓库中以文件形式存储 GitOps 代理将确保所需的软件状态已在运行时环境中部署 Argo CD 介绍 # 基于 GitOps 的 K8S 的持续性传输工具。 使用 Git Repo 作为事实来源。 声明式持续性交付工具。 支持各种配置管理工具（ksonnet、jsonnet、kustomize 和 helm）。 作为 K8S 控制器和 CRD 实现。 提供具有强大的资源管理功能的 Kubernetes 仪表板。 自动同步应用程序的当前实时状态到期望状态。 Argo CD 关键特性 # 强大、实时的网络 UI 支持多个配置管理/模板工具 多集群支持 SSO 集成 资源健康评估 自动配置漂移检测和差异 自动或手动将应用程序同步到其期望状态 自动化 CLI 和 CI 集成 审计活动 Prometheus 度量标准 GnuPG 签名验证 同步的前置/后置钩子 多租户和 RBAC 授权策略 Argo CD Application 自定义资源 # 定义了 Argo CD 做什么的核心实例是 Application 的 CR。</description>
    </item>
    <item>
      <title>pprof</title>
      <link>https://howieyuen.github.io/docs/golang/tools/pprof/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/golang/tools/pprof/</guid>
      <description>&lt;p&gt;Profiling 是指在程序执行过程中，收集能够反映程序执行状态的数据。&#xA;在软件工程中，性能分析（performance analysis，也称为 profiling），&#xA;是以收集程序运行时信息为手段研究程序行为的分析方法，是一种动态程序分析的方法。&lt;/p&gt;</description>
    </item>
    <item>
      <title>鉴权机制</title>
      <link>https://howieyuen.github.io/docs/kubernetes/kube-apiserver/authorization/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/kube-apiserver/authorization/</guid>
      <description>&lt;p&gt;在客户端请求通过认证后，会进入鉴权阶段，kube-apiserver 同样支持多种鉴权机制，并支持同时开启多个鉴权模块。&#xA;如果开启多个鉴权模块，则按照顺序执行鉴权模块，排在前面的鉴权模块有较高的优先级来允许或者拒绝请求。&#xA;只要有一个鉴权模块通过，则鉴权成功。&lt;/p&gt;</description>
    </item>
    <item>
      <title>unsafe</title>
      <link>https://howieyuen.github.io/docs/golang/language-basics/unsafe/</link>
      <pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/golang/language-basics/unsafe/</guid>
      <description>&lt;p&gt;本文转自：&#xA;  &lt;a href=&#34;https://gocn.vip/topics/371&#34;&gt;Go 里面的 unsafe 包详解&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>chan</title>
      <link>https://howieyuen.github.io/docs/golang/data-structure/chan/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/golang/data-structure/chan/</guid>
      <description>&lt;p&gt;Go 语言中最常见的、也是经常被人提及的设计模式就是 —— 不要通过共享内存的方式进行通信，而是应该通过通信的方式共享内存。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;先入先出&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;目前的 Channel 收发操作均遵循了先入先出（FIFO）的设计，具体规则如下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;先从 Channel 读取数据的 Goroutine 会先接收到数据；&lt;/li&gt;&#xA;&lt;li&gt;先向 Channel 发送数据的 Goroutine 会得到先发送数据的权利；&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>321. 拼接最大数</title>
      <link>https://howieyuen.github.io/docs/leetcode/0321/</link>
      <pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/leetcode/0321/</guid>
      <description>321. 拼接最大数 # leetcode 链接： https://leetcode-cn.com/problems/create-maximum-number/&#xA;给定长度分别为 m 和 n 的两个数组，其元素由 0-9 构成，表示两个自然数各位上的数字。现在从这两个数组中选出 k (k &amp;lt;= m + n) 个数字拼接成一个新的数，要求从同一个数组中取出的数字保持其在原数组中的相对顺序。&#xA;求满足该条件的最大数。结果返回一个表示该最大数的长度为 k 的数组。&#xA;说明：请尽可能地优化你算法的时间和空间复杂度。&#xA;示例 1:&#xA;输入： nums1 = [3, 4, 6, 5] nums2 = [9, 1, 2, 5, 8, 3] k = 5 输出： [9, 8, 6, 5, 3] 示例 2:&#xA;输入： nums1 = [6, 7] nums2 = [6, 0, 4] k = 5 输出： [6, 7, 6, 0, 4] 示例 3:</description>
    </item>
    <item>
      <title>认证机制</title>
      <link>https://howieyuen.github.io/docs/kubernetes/kube-apiserver/authentication/</link>
      <pubDate>Sun, 22 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/kube-apiserver/authentication/</guid>
      <description>所有 Kubernetes 集群都有两类用户：由 Kubernetes 管理的 ServiceAccount 和普通用户。&#xA;Kubernetes 中的用户 # 对于与普通用户，Kuernetes 使用以下方式管理：&#xA;负责分发私钥的管理员 类似 Keystone 或者 Google Accounts 这类用户数据库 包含用户名和密码列表的文件 因此，kubernetes 并不提供普通用户的定义，普通用户是无法通过 API 调用写入到集群中的。&#xA;尽管如此，通过集群的证书机构签名的合法证书的用户，kubernetes 依旧可以认为是合法用户。基于此，kubernetes 使用证书中的 subject.CommonName 字段来确定用户名，接下来，通过 RBAC 确认用户对某资源是否存在要求的操作权限。&#xA;与此不同的 ServiceAccount，与 Namespace 绑定，与一组 Secret 所包含的凭据有关。这些凭据会挂载到 Pod 中，从而允许访问 kubernetes 的 API。&#xA;API 请求要么与普通用户相关，要么与 ServiceAccount 相关，其他的视为匿名请求。这意味着集群内和集群外的每个进程向 kube-apiserver 发起请求时，都必须通过身份认证，否则会被视为匿名用户。&#xA;认证机制 # 目前 kubernetes 提供的认证机制丰富多样，尤其是身份验证，更是五花八门：&#xA;身份验证 X509 Client Cert Static Token File Bootstrap Tokens Static Password File（deprecated in v1.16） ServiceAccount Token OpenID Connect Token Webhook Token Authentication Proxy 匿名请求 用户伪装 client-go 凭据插件 身份验证策略 # X509 Client Cert # X509 客户端证书认证，也被称为 TLS 双向认证，即为服务端和客户端互相验证证书的正确性。使用此认证方式，只要是 CA 签名过的证书都能通过认证。</description>
    </item>
    <item>
      <title>GC Controller 源码分析</title>
      <link>https://howieyuen.github.io/docs/kubernetes/kube-controller-manager/code-analysis-of-garbagecollector-controller/</link>
      <pubDate>Sun, 25 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/kube-controller-manager/code-analysis-of-garbagecollector-controller/</guid>
      <description>序言 # 垃圾回收相关，可参考 这里&#xA;源码解析 # GarbageCollectorController 负责回收集群中的资源对象，要做到这一点，首先得监控所有资源。 gc controller 会监听集群中所有可删除资源的事件，这些事件会放到一个队列中，然后启动多个 worker 协程处理。 对于删除事件，则根据删除策略删除对象；其他事件，更新对象之间的依赖关系。&#xA;startGarbageCollectorController() # 首先来看 gc controller 的入口方法，也就是 kube-controller-manager 是如何启动它的。它的主要逻辑：&#xA;判断是否启用 gc controller，默认是 true 初始化 clientset，使用 discoveryClient 获取集群中所有资源 注册不考虑 gc 的资源，默认为空 调用 garbagecollector.NewGarbageCollector() 方法 初始化 gc controller 对象 调用 garbageCollector.Run() 启动 gc controller，workers 默认是 20 调用 garbageCollector.Sync() 监听集群中的资源，当出现新的资源时，同步到 minitors 中 调用 garbagecollector.NewDebugHandler() 注册 debug 接口，用来提供集群内所有对象的关联关系； // cmd/kube-controller-manager/app/core.go:538 func startGarbageCollectorController(ctx ControllerContext) (http.Handler, bool, error) { // 1. 判断是否启用 gc controller，默认是 true if !</description>
    </item>
    <item>
      <title>DaemonSet Controller 源码分析</title>
      <link>https://howieyuen.github.io/docs/kubernetes/kube-controller-manager/code-analysis-of-daemonset-controller/</link>
      <pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/kube-controller-manager/code-analysis-of-daemonset-controller/</guid>
      <description>DaemonSet 简介 # 我们知道，Deployment 是用来部署一定数量的 Pod。但是，当你希望 Pod 在集群中的每个节点上运行，并且每个节点上都需要一个 Pod 实例时，Deployment 就无法满足需求。&#xA;这类需求包括 Pod 执行系统级别与基础结构相关的操作，比如：希望在每个节点上运行日志收集器和资源监控组件。另一个典型的例子，就是 Kubernetes 自己的 kube-proxy 进程，它需要在所有节点上都运行，才能使得 Service 正常工作。&#xA;如此，DaemonSet 应运而生。它能确保集群中每个节点或者是满足某些特性的一组节点都运行一个 Pod 副本。当有新节点加入时，也会立即为它部署一个 Pod；当有节点从集群中删除时，Pod 也会被回收。删除 DaemonSet，也会删除所有关联的 Pod。&#xA;应用场景 # 在每个节点上运行集群存守护进程 在每个节点上运行日志收集守护进程 在每个节点上运行监控守护进程 一种简单的用法是为每种类型的守护进程在所有的节点上都启动一个 DaemonSet。 一个稍微复杂的用法是为同一种守护进程部署多个 DaemonSet；每个具有不同的标志，并且对不同硬件类型具有不同的内存、CPU 等要求。&#xA;基本功能 # 创建 删除 级联删除：kubectl delete ds/nginx-ds 非级联删除：kubectl delete ds/nginx-ds --cascade=false 更新 RollingUpdate OnDelete 回滚 示例 # apiVersion: apps/v1 kind: DaemonSet metadata: name: fluentd-elasticsearch namespace: kube-system labels: k8s-app: fluentd-logging spec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: tolerations: # this toleration is to have the daemonset runnable on master nodes # remove it if your masters can&amp;#39;t run pods - key: node-role.</description>
    </item>
    <item>
      <title>416. 分割等和子集</title>
      <link>https://howieyuen.github.io/docs/leetcode/0416/</link>
      <pubDate>Wed, 14 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/leetcode/0416/</guid>
      <description>416. 分割等和子集 # leetcode 链接： https://leetcode-cn.com/problems/partition-equal-subset-sum/&#xA;给定一个只包含正整数的非空数组。是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。&#xA;注意：&#xA;每个数组中的元素不会超过 100 数组的大小不会超过 200 示例 1:&#xA;输入：[1, 5, 11, 5] 输出：true 解释：数组可以分割成 [1, 5, 5] 和 [11]. 示例 2:&#xA;输入：[1, 2, 3, 5] 输出：false 解释：数组不能分割成两个元素和相等的子集。 方法一：0-1 背包问题&#xA;// 0-1 背包问题 // dp[i][target] 表示 nums[0, i] 区间内是否能找到和为 target 的组合 // 对于每个 nums[i]，如果 nums[i] &amp;lt;= target，可以选择 or 不选，但只要有一个为 true，dp[i][target]=true // dp[i][target] = dp[i-1][target] || dp[i][target-nums[i]] // 如果 nums[i] &amp;gt; target，只能不选，故： // dp[i][target] = dp[i-1][target] func canPartition(nums []int) bool { n := len(nums) if n &amp;lt; 2 { return false } sum := 0 maxNum := 0 for _, num := range nums { sum += num if num &amp;gt; maxNum { maxNum = num } } // 和为奇数 if sum%2 !</description>
    </item>
    <item>
      <title>垃圾回收</title>
      <link>https://howieyuen.github.io/docs/kubernetes/kube-apiserver/garbage-collector/</link>
      <pubDate>Wed, 14 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/kube-apiserver/garbage-collector/</guid>
      <description>序言 # 什么是垃圾回收 # 参考 Java 中的概念，垃圾回收（Garbage Collection）是 JVM 垃圾回收器提供的一种用于在空闲时间不定时回收无任何对象引用的对象占据的内存空间的一种机制。 垃圾回收回收的是无任何引用的对象占据的内存空间而不是对象本身。换言之，垃圾回收只会负责释放那些对象占有的内存。 对象是个抽象的词，包括引用和其占据的内存空间。当对象没有任何引用时其占据的内存空间随即被收回备用，此时对象也就被销毁。&#xA;因此，垃圾回收关注的是无任何引用的对象。在 kubernetes 中，对象的引用关系又是怎样的呢？&#xA;k8s 中的对象引用 # 某些 kubernetes 对象是其他一些对象的属主。例如一个 ReplicaSet 是一组 Pod 的属主；反之这组 Pod 就是此 ReplicaSet 的附属。 每个附属对象具有一个指向属主对象的 metadata.ownerReference 字段。&#xA;Kubernetes 会自动为 ReplicationController、ReplicaSet、StatefulSet、DaemonSet、Deployment、Job 和 CronJob 自动设置 ownerReference 的值。 也可以通过手动设置 ownerReference 的值，来指定属主和附属之间的关系。&#xA;先看一个 Pod 的详细信息，例如下面的配置显示 Pod 的属主是名为 my-replicaset 的 ReplicaSet：&#xA;apiVersion: v1 kind: Pod metadata: ... ownerReferences: - apiVersion: apps/v1 controller: true blockOwnerDeletion: true kind: ReplicaSet name: my-rs uid: d9607e19-f88f-11e6-a518-42010a800195 .</description>
    </item>
    <item>
      <title>Statefulset Controller 源码分析</title>
      <link>https://howieyuen.github.io/docs/kubernetes/kube-controller-manager/code-analysis-of-statefulset-controller/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/kube-controller-manager/code-analysis-of-statefulset-controller/</guid>
      <description>StatefulSet 简介 # Statefulset 是为了解决有状态服务的问题，而产生的一种资源类型（Deployment 和 ReplicaSet 是解决无状态服务而设计的）。&#xA;这里可能有人说，MySQL 是有状态服务吧，但我使用的是 Deploment 资源类型， MySQL 的数据通过 PV 的方式存储在第三方文件系统中，也能解决 MySQL 数据存储问题。&#xA;是的，如果你的 MySQL 是单节点，使用 Deployment 类型确实可以解决数据存储问题。 但是如果你的有状态服务是集群，且每个节点分片存储的情况下，Deployment 则不适用这种场景， 因为 Deployment 不会保证 Pod 的有序性，集群通常需要主节点先启动， 从节点在加入集群，Statefulset 则可以保证，其次 Deployment 资源的 Pod 内的 PVC 是共享存储的， 而 Statefulset 下的 Pod 内 PVC 是不共享存储的，每个 Pod 拥有自己的独立存储空间， 正好满足了分片的需求，实现分片的需求的前提是 Statefulset 可以保证 Pod 重新调度后还是能访问到相同的持久化数据。&#xA;适用 Statefulset 常用的服务有 Elasticsearch 集群，Mogodb 集群，Redis 集群等等。&#xA;特点 # 稳定、唯一的网络标识符&#xA;如：Redis 集群，在 Redis 集群中，它是通过槽位来存储数据的，假如：第一个节点是 0~1000，第二个节点是 1001~2000，第三个节点 2001~3000……，这就使得 Redis 集群中每个节点要通过 ID 来标识自己，如：第二个节点宕机了，重建后它必须还叫第二个节点，或者说第二个节点叫 R2，它必须还叫 R2，这样在获取 1001~2000 槽位的数据时，才能找到数据，否则 Redis 集群将无法找到这段数据。</description>
    </item>
    <item>
      <title>无状态应用滚动更新</title>
      <link>https://howieyuen.github.io/docs/kubernetes/kube-controller-manager/k8s-apps-rolling-update/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/kube-controller-manager/k8s-apps-rolling-update/</guid>
      <description>概念 # 滚动更新，通常出现在软件或者是系统中。滚动更新与传统更新的不同之处在于： 滚动更新不但提供了更新服务，而且通常还提供了滚动进度查询，滚动历史记录， 以及最重要的回滚等能力。通俗地说，就是具有系统或是软件的主动降级的能力。&#xA;Deployment 滚动更新 # Deployment 更新方式有 2 种：&#xA;RollingUpdate Recreate 其中，滚动更新是最常见的，阅读代码 pkg/controller/deployment/deployment_controller.go:648， 可以看到 2 种方式分别对应的业务逻辑：&#xA;func (dc *DeploymentController) syncDeployment(key string) error { ... switch d.Spec.Strategy.Type { case apps.RecreateDeploymentStrategyType: return dc.rolloutRecreate(d, rsList, podMap) case apps.RollingUpdateDeploymentStrategyType: return dc.rolloutRolling(d, rsList) } ... } 根据 d.Spec.Strategy.Type，若更新策略为 RollingUpdate， 则执行 dc.rolloutRecreate() 方法，具体逻辑如下：&#xA;func (dc *DeploymentController) rolloutRolling(d *apps.Deployment, rsList []*apps.ReplicaSet) error { // 1、获取所有的 rs，若没有 newRS 则创建 newRS, oldRSs, err := dc.getAllReplicaSetsAndSyncRevision(d, rsList, true) if err !</description>
    </item>
    <item>
      <title>watch 关键设计</title>
      <link>https://howieyuen.github.io/docs/kubernetes/kube-apiserver/key-design-of-etcd-watch/</link>
      <pubDate>Thu, 24 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/kube-apiserver/key-design-of-etcd-watch/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;注：本文转自 &#xA;  &lt;a href=&#34;https://www.kubernetes.org.cn/6889.html&#34;&gt;图解 kubernetes 中基于 etcd 的 watch 关键设计&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;本文介绍了 kubernetes 针对 etcd 的 watch 场景，k8s 在性能优化上面的一些设计，&#xA;逐个介绍缓存、定时器、序列化缓存、bookmark 机制、forget 机制、&#xA;针对数据的索引与 ringbuffer 等组件的场景以及解决的问题，&#xA;希望能帮助到那些对 apiserver 中的 watch 机制实现感兴趣的朋友。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Topology Manager 设计方案</title>
      <link>https://howieyuen.github.io/docs/kubernetes/kubelet/kubelet-topology-manager/</link>
      <pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/kubelet/kubelet-topology-manager/</guid>
      <description>注：本文翻译自 Node Topology Manager&#xA;概要 # 越来越多的系统将 CPU 和硬件加速器组合使用，以支撑高延迟和搞吞吐量的并行计算。 包括电信、科学计算、机器学习、金融服务和数据分析等领域的工作。这种的混血儿构成了一个高性能环境。&#xA;为了达到最优性能，需要对 CPU 隔离、内存和设备的物理位置进行优化。 然而，在 kubernetes 中，这些优化没有一个统一的组件管理。&#xA;本次建议提供一个新机制，可以协同 kubernetes 各个组件，对硬件资源的分配可以有不同的细粒度。&#xA;启发 # 当前，kubelet 中多个组件决定系统拓扑相关的分配：&#xA;CPU 管理器 CPU 管理器限制容器可以使用的 CPU。该能力，在 1.8 只实现了一种策略——静态分配。 该策略不支持在容器的生命周期内，动态上下线 CPU。 设备管理器 设备管理器将某个具体的设备分配给有该设备需求的容器。设备通常是在外围互连线上。 如果设备管理器和 CPU 管理器策略不一致，那么 CPU 和设备之间的所有通信都可能导致处理器互连结构上的额外跳转。 容器运行时（CNI） 网络接口控制器，包括 SR-IOV 虚拟功能（VF）和套接字有亲和关系，socket 不同，性能不同。 相关问题：&#xA;节点层级的硬件拓扑感知（包括 NUMA） 发现节点的 NUMA 架构 绑定特定 CPU 支持虚拟函数 提议：CPU 亲和与 NUMA 拓扑感知 注意，以上所有的关注点都只适用于多套接字系统。 内核能从底层硬件接收精确的拓扑信息（通常是通过 SLIT 表），是正确操作的前提。 更多信息请参考 ACPI 规范的 5.2.16 和 5.2.17 节。&#xA;目标 # 根据 CPU 管理器和设备管理器的输入，给容器选择最优的 NUMA 亲和节点。 集成 kubelet 中其他支持拓扑感知的组件，提供一个统一的内部接口。 非目标 # 设备间连接：根据直接设备互连来决定设备分配。此问题不同于套接字局部性。设备间的拓扑关系， 可以都在设备管理器中考虑，可以做到套接字的亲和性。实现这一策略，可以从逐渐支持任何设备之间的拓扑关系。 大页：本次提议有 2 个前提，一是集群中的节点已经预分配了大页； 二是操作系统能给容器做好本地页分配（只需要本地内存节点上有空闲的大页即可）。 容器网络接口：本次提议不包含修改 CNI。但是，如果 CNI 后续支持拓扑管理， 此次提出的方案应该具有良好的扩展性，以适配网络接口的局部性。对于特殊的网络需求， 可以使用设备插件 API 作为临时方案，以减少网络接口的局限性。 用户故事 # 故事 1: 快速虚拟化的网络功能</description>
    </item>
    <item>
      <title>高级调度</title>
      <link>https://howieyuen.github.io/docs/kubernetes/kube-scheduler/advanced-scheduling/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/kube-scheduler/advanced-scheduling/</guid>
      <description>使用 taint 和 toleration 阻止节点调度到特定节点 # taint 和 toleration # taint，是在不修改已有 Pod 的前提下，通过在节点上添加污点信息，拒绝 Pod 的部署。 只有当一个 Pod 容忍某个节点的 taint 时，才能被调度到此节点上。&#xA;显示节点 taint 信息&#xA;kubectl describe node master.k8s ... Name: master.k8s Role: Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/hostname=master.k8s Annotations: node.alpha.kubernetes.io/ttl=0 Taints: node-role.kubernetes.io/master:NoSchedule ... 主节点上包含一个污点，污点包含一个 key 和 value，以及一个 effect，格式为=:。 上面的污点信息表示，key 为 node-role.kubernetes.io/master，value 是空，effect 是 NoSchedule。&#xA;显示 Pod tolerations&#xA;kubectl describe Pod kube-proxy-as92 -n kube-system ... Tolerations: node-role.kubernetes.io/master:=NoSchedule node.alpha.kubernetes.io/notReady=:Exists:NoExecute node.alpha.kubernetes.io/unreachable=:Exists:NoExecute ... 第一个 toleration 匹配了主节点的 taint，表示允许这个 Pod 调度到主节点上。</description>
    </item>
    <item>
      <title>Eviction Manager 工作机制</title>
      <link>https://howieyuen.github.io/docs/kubernetes/kubelet/kubelet-eviction-manager/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/kubelet/kubelet-eviction-manager/</guid>
      <description>概述 # 在可用计算资源较少时，kubelet 为保证节点稳定性，会主动地结束一个或多个 pod 以回收短缺地资源， 这在处理内存和磁盘这种不可压缩资源时，驱逐 pod 回收资源的策略，显得尤为重要。 下面来具体研究下 Kubelet Eviction Policy 的工作机制。&#xA;kubelet 预先监控本节点的资源使用，防止资源被耗尽，保证节点稳定性。 kubelet 会预先 Fail N(&amp;gt;=1) 个 Pod，以回收出现紧缺的资源。 kubelet 在 Fail 一个 pod 时，kill 掉 pod 内所有 container，并设置 pod.status.phase = Failed。 kubelet 按照事先设定好的 Eviction Threshold 来触发驱逐动作，实现资源回收。 驱逐信号 # 在源码 pkg/kubelet/eviction/api/types.go 中定义了以下及几种 Eviction Signals：&#xA;Eviction Signal Description memory.available := node.status.capacity[memory] - node.stats.memory.workingSet nodefs.available := node.stats.fs.available nodefs.inodesFree := node.stats.fs.inodesFree imagefs.available := node.stats.runtime.imagefs.available imagefs.inodesFree := node.stats.runtime.imagefs.inodesFree allocatableMemory.available := pod.</description>
    </item>
    <item>
      <title>深入了解 Service</title>
      <link>https://howieyuen.github.io/docs/kubernetes/sig-network/learn-about-Service/</link>
      <pubDate>Fri, 24 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/sig-network/learn-about-Service/</guid>
      <description>基本概念 # Service 定义详解 # Service 是对一组提供相同功能的 Pods 的抽象，并为它们提供一个统一的入口。借助 Service， 应用可以方便的实现服务发现与负载均衡，并实现应用的零宕机升级。Service 通过标签来选取服务后端， 一般配合 Replication Controller 或者 Deployment 来保证后端容器的正常运行。 这些匹配标签的 Pod IP 和端口列表组成 endpoints， 由 kube-proxy 负责将服务 IP 负载均衡到这些 endpoints 上。&#xA;apiVersion: v1 kind: Service metadata: name: string namespace: string labels: - name: string annotations: - name: string spec: selector: [] # ClusterIP、NodePort、LoadBalancer type: string # type=ClusterIP, 有自动分配的能力；type=LoadBalancer，需指定 clusterIP: string # 是否支持 session，默认为空，可选值 ClutserIP，同一个 client 的 request，都发送到同一个后端 Pod sessionAffinity: string ports: - name: string # tcp、udp，默认 tcp protocol: string port: int targetPort: int nodePort: int # spec.</description>
    </item>
    <item>
      <title>CRD 入门和使用</title>
      <link>https://howieyuen.github.io/docs/kubernetes/kube-apiserver/crd/</link>
      <pubDate>Mon, 14 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/kubernetes/kube-apiserver/crd/</guid>
      <description>&lt;p&gt;自定义资源是 Kubernetes API 的扩展，本文将讨什么时候应该向 Kubernetes 集群添加自定义资源以及何时使用独立服务。它描述了添加自定义资源的两种方法以及如何在它们之间进行选择。&lt;/p&gt;</description>
    </item>
    <item>
      <title>External Secrets Operator</title>
      <link>https://howieyuen.github.io/docs/XaC/secret-as-code/external-secret-operator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/XaC/secret-as-code/external-secret-operator/</guid>
      <description>概述 # External Secrets Operator（ESO）是一个 Kubernetes Operator，它支持：&#xA;AWS Secrets Manager HashiCorp Vault Google Secrets Manager Azure Key Vault IBM Cloud Secret Manager &amp;hellip; 等外部 Secret 管理系统。Operator 从外部 API 读取信息并自动将值注入 Kubernetes Secret。 ESO 的目标是将来自外部 API 的机密信息同步到 Kubernetes。ESO 是自定义 API 资源的集合：&#xA;SecretStore ExternalSecret ClusterSecretStore ClusterExternalSecret 它们为外部 API 提供了一个用户友好的抽象，帮助用户存储 Secret 并管理它的生命周期。&#xA;SecretStore # SecretStore 将身份验证/访问的关注点与工作负载所需的实际 Secret 和配置分开。ExternalSecret 指定要获取的内容，SecretStore 指定如何访问。Namespace 级别。&#xA;下面的代码示例是以 Vault 作为后端，使用静态 token：&#xA;ExternalSecret # ExternalSecret 声明要获取的数据。它引用了一个知道如何访问该数据的 SecretStore。控制器使用该 ExternalSecret 作为创建 Secret 的蓝本。Namespace 级别。</description>
    </item>
    <item>
      <title>map</title>
      <link>https://howieyuen.github.io/docs/golang/data-structure/map/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/golang/data-structure/map/</guid>
      <description>&lt;p&gt;粗略的讲，Go 语言中 map 采用的是哈希查找表，&#xA;由一个 key 通过哈希函数得到哈希值，&#xA;64 位系统中就生成一个 64 bit 的哈希值，&#xA;由这个哈希值将 key 对应到不同的桶（bucket）中，&#xA;当有多个哈希映射到相同的的桶中时，使用链表解决哈希冲突。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Prometheus Operator 设计文档</title>
      <link>https://howieyuen.github.io/posts/prometheus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/posts/prometheus/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;原文链接：&#xA;  &lt;a href=&#34;https://prometheus-operator.dev/docs/operator/design/&#34;&gt;https://prometheus-operator.dev/docs/operator/design/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;本文将阐述 Prometheus Operator 管理的 CRD 之间的设计和交互。由 Prometheus Operator 管理的 CRD 有：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;  &lt;a href=&#34;https://prometheus-operator.dev/docs/operator/design/#prometheus&#34;&gt;Prometheus&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;  &lt;a href=&#34;https://prometheus-operator.dev/docs/operator/design/#alertmanager&#34;&gt;Alertmanager&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;  &lt;a href=&#34;https://prometheus-operator.dev/docs/operator/design/#thanosruler&#34;&gt;ThanosRuler&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;  &lt;a href=&#34;https://prometheus-operator.dev/docs/operator/design/#servicemonitor&#34;&gt;ServiceMonitor&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;  &lt;a href=&#34;https://prometheus-operator.dev/docs/operator/design/#podmonitor&#34;&gt;PodMonitor&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;  &lt;a href=&#34;https://prometheus-operator.dev/docs/operator/design/#probe&#34;&gt;Probe&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;  &lt;a href=&#34;https://prometheus-operator.dev/docs/operator/design/#prometheusrule&#34;&gt;PrometheusRule&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;  &lt;a href=&#34;https://prometheus-operator.dev/docs/operator/design/#alertmanagerconfig&#34;&gt;AlertmanagerConfig&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>reflect</title>
      <link>https://howieyuen.github.io/docs/golang/language-basics/reflect/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/golang/language-basics/reflect/</guid>
      <description>&lt;p&gt;计算机中提到的反射一般是指，&lt;strong&gt;程序借助某种手段检查自己结构的一种能力&lt;/strong&gt;，通常就是借助编程语言中定义的类型（&lt;code&gt;types&lt;/code&gt;）。因此，反射是建立在类型系统上的。&lt;/p&gt;</description>
    </item>
    <item>
      <title>slice</title>
      <link>https://howieyuen.github.io/docs/golang/data-structure/slice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/golang/data-structure/slice/</guid>
      <description>&lt;p&gt;slice 的底层数据是数组，slice 是对数组的封装，它描述一个数组的片段。两者都可以通过下标来访问单个元素。&#xA;数组是定长的，长度定义好之后，不能再更改。在 Go 中，数组是不常见的，因为其长度是类型的一部分，&#xA;限制了它的表达能力，比如 &lt;code&gt;[3]int&lt;/code&gt; 和 &lt;code&gt;[4]int&lt;/code&gt; 就是不同的类型。&#xA;而切片则非常灵活，它可以动态地扩容。切片的类型和长度无关。&#xA;数组就是一片连续的内存， slice 实际上是一个结构体，包含三个字段：长度、容量、底层数组。&lt;/p&gt;</description>
    </item>
    <item>
      <title>内存模型</title>
      <link>https://howieyuen.github.io/docs/golang/memory-manage/memory-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://howieyuen.github.io/docs/golang/memory-manage/memory-model/</guid>
      <description>&lt;p&gt;Go 语言的内存模型规定了一个 goroutine 可以看到另外一个 goroutine 修改同一个变量的值的条件，&#xA;这类似 java 内存模型中内存可见性问题。当多个 goroutine 并发同时存取同一个数据时候必须把并发的存取的操作顺序化，&#xA;在 go 中可以实现操作顺序化的工具有高级的通道（channel）通信和同步原语比如 sync 包中的互斥锁（Mutex）、&#xA;读写锁（RWMutex）或者和 sync/atomic 中的原子操作。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
