<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>介绍 on 袁昊的学习笔记</title>
    <link>https://howieyuen.github.io/</link>
    <description>Recent content in 介绍 on 袁昊的学习笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 12 Oct 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://howieyuen.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>k8s应用滚动更新</title>
      <link>https://howieyuen.github.io/docs/kubernetes/sig-apps/k8s-apps-rolling-update/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://howieyuen.github.io/docs/kubernetes/sig-apps/k8s-apps-rolling-update/</guid>
      <description>1. 概念 #  滚动更新，通常出现在软件或者是系统中。滚动更新与传统更新的不同之处在于：滚动更新不但提供了更新服务，而且通常还提供了滚动进度查询， 滚动历史记录，以及最重要的回滚等能力。通俗地说，就是具有系统或是软件的主动降级的能力。
2. Deployment 滚动更新 #  Deployment更新方式有 2 种：
 RollingUpdate Recreate  其中，滚动更新是最常见的，阅读代码 pkg/controller/deployment/deployment_controller.go:648，可以看到 2 种方式分别对应的业务逻辑：
func (dc *DeploymentController) syncDeployment(key string) error { ... switch d.Spec.Strategy.Type { case apps.RecreateDeploymentStrategyType: return dc.rolloutRecreate(d, rsList, podMap) case apps.RollingUpdateDeploymentStrategyType: return dc.rolloutRolling(d, rsList) } ... } 根据 d.Spec.Strategy.Type，若更新策略为 RollingUpdate，则执行 dc.rolloutRecreate() 方法，具体逻辑如下：
func (dc *DeploymentController) rolloutRolling(d *apps.Deployment, rsList []*apps.ReplicaSet) error { // 1、获取所有的 rs，若没有 newRS 则创建 	newRS, oldRSs, err := dc.</description>
    </item>
    
    <item>
      <title>ETCD watch 关键设计</title>
      <link>https://howieyuen.github.io/docs/kubernetes/sig-api-machinery/key-design-of-etcd-watch/</link>
      <pubDate>Thu, 24 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://howieyuen.github.io/docs/kubernetes/sig-api-machinery/key-design-of-etcd-watch/</guid>
      <description>注：本文转自 图解kubernetes中基于etcd的watch关键设计
 本文介绍了kubernetes针对etcd的watch场景，k8s在性能优化上面的一些设计，逐个介绍缓存、定时器、序列化缓存、bookmark机制、forget机制、针对数据的索引与ringbuffer等组件的场景以及解决的问题，希望能帮助到那些对apiserver中的watch机制实现感兴趣的朋友。
1. 事件驱动与控制器 #   k8s中并没有将业务的具体处理逻辑耦合在rest接口中，rest接口只负责数据的存储，通过控制器模式，分离数据存储与业务逻辑的耦合，保证apiserver业务逻辑的简洁。
 控制器通过watch接口来感知对应的资源的数据变更，从而根据资源对象中的期望状态与当前状态之间的差异，来决策业务逻辑的控制，watch本质上做的事情其实就是将感知到的事件发生给关注该事件的控制器。
2. Watch的核心机制 #  这里我们先介绍基于etcd实现的基础的watch模块。
2.1 事件类型与etcd #   一个数据变更本质上无非就是三种类型：新增、更新和删除，其中新增和删除都比较容易因为都可以通过当前数据获取，而更新则可能需要获取之前的数据，这里其实就是借助了etcd中revision和mvcc机制来实现，这样就可以获取到之前的状态和更新后的状态，并且获取后续的通知。
2.2 事件管道 #   事件管道则是负责事件的传递，在watch的实现中通过两级管道来实现消息的分发，首先通过watch etcd中的key获取感兴趣的事件，并进行数据的解析，完成从bytes到内部事件的转换并且发送到输入管道(incomingEventChan)中，然后后台会有线程负责输入管道中获取数据，并进行解析发送到输出管道(resultChan)中，后续会从该管道来进行事件的读取发送给对应的客户端。
2.3 事件缓冲区 #  事件缓冲区是指的如果对应的事件处理程序与当前事件发生的速率不匹配的时候，则需要一定的buffer来暂存因为速率不匹配的事件， 在go里面大家通常使用一个有缓冲的channel构建。
 到这里基本上就实现了一个基本可用的watch服务，通过etcd的watch接口监听数据，然后启动独立goroutine来进行事件的消费，并且发送到事件管道供其他接口调用。
3. Cacher #  kubernetes中所有的数据和系统都基于etcd来实现，如何减轻访问压力呢，答案就是缓存，watch也是这样，本节我们来看看如何实现watch缓存机制的实现，这里的cacher是针对
3.1 Reflector #   Reflector是client-go中的一个组件，其通过listwatch接口获取数据存储在自己内部的store中，cacher中通过该组件对etcd进行watch操作，避免为每个组件都创建一个etcd的watcher。
3.2 watchCache #   wacthCache负责存储watch到的事件，并且将watch的事件建立对应的本地索引缓存，同时在构建watchCache还负责将事件的传递，其将watch到的事件通过eventHandler来传递给上层的Cacher组件。
3.3 cacheWatcher #   cacheWatcher顾名思义其是就是针对cache的一个watcher(watch.Interface)实现， 前端的watchServer负责从ResultChan里面获取事件进行转发。
3.4 Cacher #   Cacher基于etcd的store结合上面的watchCache和Reflector共同构建带缓存的REST store， 针对普通的增删改功能其直接转发给etcd的store来进行底层的操作，而对于watch操作则进行拦截，构建并返回cacheWatcher组件。</description>
    </item>
    
    <item>
      <title>kubelet topology manager</title>
      <link>https://howieyuen.github.io/docs/kubernetes/sig-node/topology-manager/</link>
      <pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://howieyuen.github.io/docs/kubernetes/sig-node/topology-manager/</guid>
      <description>注：本文翻译自 Node Topology Manager
 1. 概要 #  越来越多的系统将CPU和硬件加速器组合使用，以支撑高延迟和搞吞吐量的并行计算。包括电信、科学计算、机器学习、金融服务和数据分析等领域的工作。这种的混血儿构成了一个高性能环境。
为了达到最优性能，需要对CPU隔离、内存和设备的物理位置进行优化。然而，在kubernetes中，这些优化没有一个统一的组件管理。
本次建议提供一个新机制，可以协同kubernetes各个组件，对硬件资源的分配可以有不同的细粒度。
2. 启发 #  当前，kubelet中多个组件决定系统拓扑相关的分配：
 CPU 管理器  CPU管理器限制容器可以使用的CPU。该能力，在1.8只实现了一种策略——静态分配。该策略不支持在容器的生命周期内，动态上下线CPU。   设备管理器  设备管理器将某个具体的设备分配给有该设备需求的容器。设备通常是在外围互连线上。如果设备管理器和CPU管理器策略不一致，那么CPU和设备之间的所有通信都可能导致处理器互连结构上的额外跳转。   容器运行时（CNI）  网络接口控制器，包括SR-IOV虚拟功能（VF）和套接字有亲和关系，socket不同，性能不同。    相关问题：
  节点层级的硬件拓扑感知（包括NUMA）  发现节点的NUMA架构  绑定特定CPU支持虚拟函数  提议：CPU亲和与NUMA拓扑感知  注意，以上所有的关注点都只适用于多套接字系统。内核能从底层硬件接收精确的拓扑信息（通常是通过SLIT表），是正确操作的前提。更多信息请参考ACPI规范的5.2.16和5.2.17节。
2.1 目标 #   根据CPU管理器和设备管理器的输入，给容器选择最优的NUMA亲和节点。 集成kubelet中其他支持拓扑感知的组件，提供一个统一的内部接口。  2.2 非目标 #   设备间连接：根据直接设备互连来决定设备分配。此问题不同于套接字局部性。设备间的拓扑关系，可以都在设备管理器中考虑，可以做到套接字的亲和性。实现这一策略，可以从逐渐支持任何设备之间的拓扑关系。 大页：本次提议有2个前提，一是集群中的节点已经预分配了大页；二是操作系统能给容器做好本地页分配（只需要本地内存节点上有空闲的大页即可） 容器网络接口：本次提议不包含修改CNI。但是，如果CNI后续支持拓扑管理，此次提出的方案应该具有良好的扩展性，以适配网络接口的局部性。对于特殊的网络需求，可以使用设备插件API作为临时方案，以减少网络接口的局限性。  2.3 用户故事 #  故事1: 快速虚拟化的网络功能</description>
    </item>
    
    <item>
      <title>高级调度</title>
      <link>https://howieyuen.github.io/docs/kubernetes/sig-scheduling/advanced-scheduling/</link>
      <pubDate>Sun, 22 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://howieyuen.github.io/docs/kubernetes/sig-scheduling/advanced-scheduling/</guid>
      <description>1. 使用taint和toleration阻止节点调度到特定节点 #  1.1 taint和toleration #  taint，是在不修改已有pod的前提下，通过在节点上添加污点信息，拒绝pod的部署。只有当一个pod容忍某个节点的taint时，才能被调度到此节点上。
显示节点taint信息
kubectl describe node master.k8s ... Name: master.k8s Role: Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/hostname=master.k8s Annotations: node.alpha.kubernetes.io/ttl=0 Taints: node-role.kubernetes.io/master:NoSchedule ... 主节点上包含一个污点，污点包含一个key和value，以及一个effect，格式为=:。上面的污点信息表示，key为node-role.kubernetes.io/master，value是空，effect是NoSchedule。
显示pod tolerations
kubectl describe pod kube-proxy-as92 -n kube-system ... Tolerations: node-role.kubernetes.io/master:=NoSchedule node.alpha.kubernetes.io/notReady=:Exists:NoExecute node.alpha.kubernetes.io/unreachable=:Exists:NoExecute ... 第一个toleration匹配了主节点的taint，表示允许这个pod调度到主节点上。
了解污点效果 另外2个在kube-proxy pod上容忍定义了当前节点状态是没有ready或者是unreachable时，该pod允许运行在该节点上多长时间。 污点可以包含以下三种效果：
 NoSchedule，表示如果pod没有容忍此污点，将无法调度 PreferNoSchedule，是上面的宽松版本，如果没有其他节点可调度，依旧可以调度到本节点 NoExecute，上2个在调度期间起作用，而此设定也会影响正在运行中的pod。如果节点上的pod没有容忍此污点，会被驱逐。   1.2 在节点上定义污点 #  kubectl taint node node1.k8s node-type=production:NoSchedule 此命令给节点添加污点，key为node-type，value为production，effect为NoSchedule。如果现在部署一个常规pod多个副本，没有一个pod会调度到此节点上。
1.3 在pod上添加容忍 #  apiVersion: apps/v1 kind: Deployment metadata: name: prod spec: replicas: 5 template: spec: .</description>
    </item>
    
    <item>
      <title>深入了解 Service</title>
      <link>https://howieyuen.github.io/docs/kubernetes/sig-network/learn-about-Service/</link>
      <pubDate>Fri, 24 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://howieyuen.github.io/docs/kubernetes/sig-network/learn-about-Service/</guid>
      <description>一、基本概念 #  1.1 Service 定义详解 #  Service 是对一组提供相同功能的 Pods 的抽象，并为它们提供一个统一的入口。借助 Service，应用可以方便的实现服务发现与负载均衡，并实现应用的零宕机升级。Service 通过标签来选取服务后端，一般配合 Replication Controller 或者 Deployment 来保证后端容器的正常运行。这些匹配标签的 Pod IP 和端口列表组成 endpoints，由 kube-proxy 负责将服务 IP 负载均衡到这些 endpoints 上。
apiVersion: v1 kind: Service metadata: name: string namespace: string labels: - name: string annotations: - name: string spec: selector: [] type: string // ClusterIP、NodePort、LoadBalancer clusterIP: string // type=ClusterIP, 有自动分配的能力；type=LoadBalancer，需指定 sessionAffinity: string // 是否支持session，默认为空，可选值ClutserIP，同一个client的request，都发送到同一个后端pod ports: - name: string protocol: string // tcp、udp，默认tcp port: int targetPort: int nodePort: int status: // spec.</description>
    </item>
    
    <item>
      <title>kubelet eviction manager</title>
      <link>https://howieyuen.github.io/docs/kubernetes/sig-node/kubelet-eviction-manager/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://howieyuen.github.io/docs/kubernetes/sig-node/kubelet-eviction-manager/</guid>
      <description>1、概述 #  在可用计算资源较少时，kubelet为保证节点稳定性，会主动地结束一个或多个pod以回收短缺地资源，这在处理内存和磁盘这种不可压缩资源时，驱逐pod回收资源的策略，显得尤为重要。下面来具体研究下Kubelet Eviction Policy的工作机制。
 kubelet预先监控本节点的资源使用，防止资源被耗尽，保证节点稳定性。 kubelet会预先Fail N(&amp;gt;=1)个Pod，以回收出现紧缺的资源。 kubelet在Fail一个pod时，kill掉pod内所有container，并设置pod.status.phase = Failed。 kubelet按照事先设定好的Eviction Threshold来触发驱逐动作，实现资源回收。  1.1 驱逐信号 #  在源码pkg/kubelet/eviction/api/types.go中定义了以下及几种Eviction Signals：
   Eviction Signal Description     memory.available := node.status.capacity[memory] - node.stats.memory.workingSet   nodefs.available := node.stats.fs.available   nodefs.inodesFree := node.stats.fs.inodesFree   imagefs.available := node.stats.runtime.imagefs.available   imagefs.inodesFree := node.stats.runtime.imagefs.inodesFree   allocatableMemory.available := pod.allocatable - pod.workingSet   pid.available := node.MaxPID - node.</description>
    </item>
    
  </channel>
</rss>
