'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/kubernetes/sig-apps/k8s-apps-rolling-update/','title':"k8s应用滚动更新",'section':"sig-apps",'content':"1. 概念 #  滚动更新，通常出现在软件或者是系统中。滚动更新与传统更新的不同之处在于：滚动更新不但提供了更新服务，而且通常还提供了滚动进度查询， 滚动历史记录，以及最重要的回滚等能力。通俗地说，就是具有系统或是软件的主动降级的能力。\n2. Deployment 滚动更新 #  Deployment更新方式有 2 种：\n RollingUpdate Recreate  其中，滚动更新是最常见的，阅读代码 pkg/controller/deployment/deployment_controller.go:648，可以看到 2 种方式分别对应的业务逻辑：\nfunc (dc *DeploymentController) syncDeployment(key string) error { ... switch d.Spec.Strategy.Type { case apps.RecreateDeploymentStrategyType: return dc.rolloutRecreate(d, rsList, podMap) case apps.RollingUpdateDeploymentStrategyType: return dc.rolloutRolling(d, rsList) } ... } 根据 d.Spec.Strategy.Type，若更新策略为 RollingUpdate，则执行 dc.rolloutRecreate() 方法，具体逻辑如下：\nfunc (dc *DeploymentController) rolloutRolling(d *apps.Deployment, rsList []*apps.ReplicaSet) error { // 1、获取所有的 rs，若没有 newRS 则创建 \tnewRS, oldRSs, err := dc.getAllReplicaSetsAndSyncRevision(d, rsList, true) if err != nil { return err } allRSs := append(oldRSs, newRS) // 2、newRS 执行 scale up 操作 \tscaledUp, err := dc.reconcileNewReplicaSet(allRSs, newRS, d) if err != nil { return err } if scaledUp { // Update DeploymentStatus \treturn dc.syncRolloutStatus(allRSs, newRS, d) } // 3、oldRS 执行 scale down 操作 \tscaledDown, err := dc.reconcileOldReplicaSets(allRSs, controller.FilterActiveReplicaSets(oldRSs), newRS, d) if err != nil { return err } if scaledDown { // Update DeploymentStatus \treturn dc.syncRolloutStatus(allRSs, newRS, d) } // 4、清理过期的 rs \tif deploymentutil.DeploymentComplete(d, \u0026amp;d.Status) { if err := dc.cleanupDeployment(oldRSs, d); err != nil { return err } } // 5、同步 deployment 状态 \treturn dc.syncRolloutStatus(allRSs, newRS, d) } 2.1 滚动更新概述 #  上面代码中5个重要的步骤总结如下：\n 调用 getAllReplicaSetsAndSyncRevision() 获取所有的 rs，若没有 newRS 则创建； 调用 reconcileNewReplicaSet() 判断是否需要对 newRS 进行 scaleUp 操作；如果需要 scaleUp，更新 Deployment 的 status， 添加相关的 condition，该 condition 的 type 是 Progressing，表明该 deployment 正在更新中，然后直接返回； 调用 reconcileOldReplicaSets() 判断是否需要为 oldRS 进行 scaleDown 操作；如果需要 scaleDown， 把 oldRS 关联的 pod 删掉 maxScaledDown 个，然后更新 Deployment 的 status，添加相关的 condition，直接返回。 这样一来就保证了在滚动更新过程中，新老版本的 Pod 都存在； 如果两者都不是则滚动升级很可能已经完成，此时需要检查 deployment.Status 是否已经达到期望状态， 并且根据 deployment.Spec.RevisionHistoryLimit 的值清理 oldRSs； 最后，同步 deployment 的状态，使其与期望一致；  从上面的步骤可以看出，滚动更新的过程主要分成一下三个阶段：\n mermaid.initialize({ \"flowchart\": { \"useMaxWidth\":true }, \"theme\": \"default\" } ) graph LR\rstart((开始)) -- condtion1{newRS need scale up ?}\rcondtion1 -- No -- condtion2{oldRS need scale down ?}\rcondtion2 -- NO -- x3(3. sync deploment status)\rcondtion1 -- YES -- x1(1. newRS scale up)\rx1 -- stop((结束))\rcondtion2 -- YES -- x2(2. oldRS scale down)\rx2 -- stop\rx3 -- stop\r2.1.1 newRS scale up #  阅读代码 pkg/controller/deployment/rolling.go:68，详细如下：\nfunc (dc *DeploymentController) reconcileNewReplicaSet(allRSs []*apps.ReplicaSet, newRS *apps.ReplicaSet, deployment *apps.Deployment) (bool, error) { // 1、判断副本数是否已达到了期望值 \tif *(newRS.Spec.Replicas) == *(deployment.Spec.Replicas) { // Scaling not required. \treturn false, nil } // 2、判断是否需要 scale down 操作 \tif *(newRS.Spec.Replicas) \u0026gt; *(deployment.Spec.Replicas) { // Scale down. \tscaled, _, err := dc.scaleReplicaSetAndRecordEvent(newRS, *(deployment.Spec.Replicas), deployment) return scaled, err } // 3、计算 newRS 所需要的副本数 \tnewReplicasCount, err := deploymentutil.NewRSNewReplicas(deployment, allRSs, newRS) if err != nil { return false, err } // 4、如果需要 scale ，则更新 rs 的 annotation 以及 rs.Spec.Replicas \tscaled, _, err := dc.scaleReplicaSetAndRecordEvent(newRS, newReplicasCount, deployment) return scaled, err } 从上面的源码可以得出，reconcileNewReplicaSet() 的主要逻辑如下：\n 判断 newRS.Spec.Replicas 和 deployment.Spec.Replicas 是否相等，如果相等则直接返回，说明已经达到期望状态； 若 newRS.Spec.Replicas \u0026gt; deployment.Spec.Replicas，则说明 newRS 副本数已经超过期望值， 调用 dc.scaleReplicaSetAndRecordEvent() 进行 scale down； 此时 newRS.Spec.Replicas \u0026lt; deployment.Spec.Replicas， 调用 deploymentutil.NewRSNewReplicas() 为 newRS 计算所需要的副本数，计算原则遵守 maxSurge 和 maxUnavailable 的约束； 调用 dc.scaleReplicaSetAndRecordEvent() 更新 newRS 对象，设置 rs.Spec.Replicas、rs.Annotations[DesiredReplicasAnnotation] 以及 rs.Annotations[MaxReplicasAnnotation]；  其中，计算 newRS 的副本数，是滚动更新核心过程的第一步，阅读源码 pkg/controller/deployment/util/deployment_util.go:816：\nfunc NewRSNewReplicas(deployment *apps.Deployment, allRSs []*apps.ReplicaSet, newRS *apps.ReplicaSet) (int32, error) { switch deployment.Spec.Strategy.Type { case apps.RollingUpdateDeploymentStrategyType: // 1、计算 maxSurge 值，向上取整 \tmaxSurge, err := intstrutil.GetValueFromIntOrPercent(deployment.Spec.Strategy.RollingUpdate.MaxSurge, int(*(deployment.Spec.Replicas)), true) if err != nil { return 0, err } // 2、累加 rs.Spec.Replicas 获取 currentPodCount \tcurrentPodCount := GetReplicaCountForReplicaSets(allRSs) maxTotalPods := *(deployment.Spec.Replicas) + int32(maxSurge) if currentPodCount \u0026gt;= maxTotalPods { // Cannot scale up. \treturn *(newRS.Spec.Replicas), nil } // 3、计算 scaleUpCount，结果不超过期望值 \tscaleUpCount := maxTotalPods - currentPodCount scaleUpCount = int32(integer.IntMin(int(scaleUpCount), int(*(deployment.Spec.Replicas)-*(newRS.Spec.Replicas)))) return *(newRS.Spec.Replicas) + scaleUpCount, nil case apps.RecreateDeploymentStrategyType: return *(deployment.Spec.Replicas), nil default: return 0, fmt.Errorf(\u0026#34;deployment type %v isn\u0026#39;t supported\u0026#34;, deployment.Spec.Strategy.Type) } } 可知 NewRSNewReplicas() 的主要逻辑如下：\n 判断更新策略； 计算 maxSurge 值； 通过 allRSs 计算 currentPodCount 的值； 最后计算 scaleUpCount 值；  2.1.2 oldRS scale down #  同理，oldRS 规模缩小，阅读源码 pkg/controller/deployment/rolling.go:68:\nfunc (dc *DeploymentController) reconcileOldReplicaSets(allRSs []*apps.ReplicaSet, oldRSs []*apps.ReplicaSet, newRS *apps.ReplicaSet, deployment *apps.Deployment) (bool, error) { // 1、计算 oldPodsCount \toldPodsCount := deploymentutil.GetReplicaCountForReplicaSets(oldRSs) if oldPodsCount == 0 { // Can\u0026#39;t scale down further \treturn false, nil } // 2、计算 maxUnavailable \tallPodsCount := deploymentutil.GetReplicaCountForReplicaSets(allRSs) klog.V(4).Infof(\u0026#34;New replica set %s/%s has %d available pods.\u0026#34;, newRS.Namespace, newRS.Name, newRS.Status.AvailableReplicas) maxUnavailable := deploymentutil.MaxUnavailable(*deployment) // 3、计算 maxScaledDown \tminAvailable := *(deployment.Spec.Replicas) - maxUnavailable newRSUnavailablePodCount := *(newRS.Spec.Replicas) - newRS.Status.AvailableReplicas maxScaledDown := allPodsCount - minAvailable - newRSUnavailablePodCount if maxScaledDown \u0026lt;= 0 { return false, nil } // 4、清理异常的 rs \toldRSs, cleanupCount, err := dc.cleanupUnhealthyReplicas(oldRSs, deployment, maxScaledDown) if err != nil { return false, nil } klog.V(4).Infof(\u0026#34;Cleaned up unhealthy replicas from old RSes by %d\u0026#34;, cleanupCount) // 5、缩容 old rs \tallRSs = append(oldRSs, newRS) scaledDownCount, err := dc.scaleDownOldReplicaSetsForRollingUpdate(allRSs, oldRSs, deployment) if err != nil { return false, nil } klog.V(4).Infof(\u0026#34;Scaled down old RSes of deployment %s by %d\u0026#34;, deployment.Name, scaledDownCount) totalScaledDown := cleanupCount + scaledDownCount return totalScaledDown \u0026gt; 0, nil } 通过上面的代码可知，reconcileOldReplicaSets() 的主要逻辑如下：\n 通过 oldRSs 和 allRSs 获取 oldPodsCount 和 allPodsCount； 计算 deployment 的 maxUnavailable、minAvailable、newRSUnavailablePodCount、maxScaledDown 值， 当 deployment 的 maxSurge 和 maxUnavailable 值为百分数时，计算 maxSurge 向上取整而 maxUnavailable 则向下取整； 清理异常的 rs； 计算 oldRS 的 scaleDownCount； 最后 oldRS 缩容；  2.2 滚动更新总结 #  通过上面的代码可以看出，滚动更新过程中主要是通过调用 reconcileNewReplicaSet() 对 newRS 不断扩容， 调用 reconcileOldReplicaSets() 对 oldRS 不断缩容，最终达到期望状态，并且在整个升级过程中， 都严格遵守 maxSurge 和 maxUnavailable 的约束。\n不论是在 scale up 或者 scale down 中都是调用 scaleReplicaSetAndRecordEvent() 执行， 而 scaleReplicaSetAndRecordEvent() 又会调用 scaleReplicaSet()， 扩缩容都是更新 rs.Annotations 以及 rs.Spec.Replicas。\n整体流程如下图所示：\ngraph LR\rop1(newRS scale up) -- op3[dc.scaleReplicaSetAndRecordEvent]\rop2(oldRS scale down) -- op3(dc.scaleReplicaSetAndRecordEvent)\rop3(dc.scaleReplicaSetAndRecordEvent) -- op4(dc.scaleReplicaSet)\r2.3 滚动更新示例 #  "});index.add({'id':1,'href':'/docs/kubernetes/sig-api-machinery/key-design-of-etcd-watch/','title':"ETCD watch 关键设计",'section':"sig-api-machinery",'content':" 注：本文转自 图解kubernetes中基于etcd的watch关键设计\n 本文介绍了kubernetes针对etcd的watch场景，k8s在性能优化上面的一些设计，逐个介绍缓存、定时器、序列化缓存、bookmark机制、forget机制、针对数据的索引与ringbuffer等组件的场景以及解决的问题，希望能帮助到那些对apiserver中的watch机制实现感兴趣的朋友。\n1. 事件驱动与控制器 #   k8s中并没有将业务的具体处理逻辑耦合在rest接口中，rest接口只负责数据的存储，通过控制器模式，分离数据存储与业务逻辑的耦合，保证apiserver业务逻辑的简洁。\n 控制器通过watch接口来感知对应的资源的数据变更，从而根据资源对象中的期望状态与当前状态之间的差异，来决策业务逻辑的控制，watch本质上做的事情其实就是将感知到的事件发生给关注该事件的控制器。\n2. Watch的核心机制 #  这里我们先介绍基于etcd实现的基础的watch模块。\n2.1 事件类型与etcd #   一个数据变更本质上无非就是三种类型：新增、更新和删除，其中新增和删除都比较容易因为都可以通过当前数据获取，而更新则可能需要获取之前的数据，这里其实就是借助了etcd中revision和mvcc机制来实现，这样就可以获取到之前的状态和更新后的状态，并且获取后续的通知。\n2.2 事件管道 #   事件管道则是负责事件的传递，在watch的实现中通过两级管道来实现消息的分发，首先通过watch etcd中的key获取感兴趣的事件，并进行数据的解析，完成从bytes到内部事件的转换并且发送到输入管道(incomingEventChan)中，然后后台会有线程负责输入管道中获取数据，并进行解析发送到输出管道(resultChan)中，后续会从该管道来进行事件的读取发送给对应的客户端。\n2.3 事件缓冲区 #  事件缓冲区是指的如果对应的事件处理程序与当前事件发生的速率不匹配的时候，则需要一定的buffer来暂存因为速率不匹配的事件， 在go里面大家通常使用一个有缓冲的channel构建。\n 到这里基本上就实现了一个基本可用的watch服务，通过etcd的watch接口监听数据，然后启动独立goroutine来进行事件的消费，并且发送到事件管道供其他接口调用。\n3. Cacher #  kubernetes中所有的数据和系统都基于etcd来实现，如何减轻访问压力呢，答案就是缓存，watch也是这样，本节我们来看看如何实现watch缓存机制的实现，这里的cacher是针对\n3.1 Reflector #   Reflector是client-go中的一个组件，其通过listwatch接口获取数据存储在自己内部的store中，cacher中通过该组件对etcd进行watch操作，避免为每个组件都创建一个etcd的watcher。\n3.2 watchCache #   wacthCache负责存储watch到的事件，并且将watch的事件建立对应的本地索引缓存，同时在构建watchCache还负责将事件的传递，其将watch到的事件通过eventHandler来传递给上层的Cacher组件。\n3.3 cacheWatcher #   cacheWatcher顾名思义其是就是针对cache的一个watcher(watch.Interface)实现， 前端的watchServer负责从ResultChan里面获取事件进行转发。\n3.4 Cacher #   Cacher基于etcd的store结合上面的watchCache和Reflector共同构建带缓存的REST store， 针对普通的增删改功能其直接转发给etcd的store来进行底层的操作，而对于watch操作则进行拦截，构建并返回cacheWatcher组件。\n4. Cacher的优化 #  看完基础组件的实现，接着我们看下针对watch这个场景k8s中还做了那些优化，学习针对类似场景的优化方案。\n4.1 序列化缓存 #   如果我们有多个watcher都wacth同一个事件，在最终的时候我们都需要进行序列化，cacher中在分发的时候，如果发现超过指定数量的watcher， 则会在进行dispatch的时候，为其构建构建一个缓存函数，针对多个watcher只会进行一次的序列化。\n4.2 nonblocking #   在上面我们提到过事件缓冲区，但是如果某个watcher消费过慢依然会影响事件的分发，为此cacher中通过是否阻塞(是否可以直接将数据写入到管道中)来将watcher分为两类，针对不能立即投递事件的watcher， 则会在后续进行重试。\n4.3 TimeBudget #  针对阻塞的watcher在进行重试的时候，会通过dispatchTimeoutBudget构建一个定时器来进行超时控制， 那什么叫Budget呢，其实如果在这段时间内，如果重试立马就成功，则本次剩余的时间，在下一次进行定时的时候，则可以使用之前剩余的余额，但是后台也还有个线程，用于周期性重置。\n4.4 forget机制 #   针对上面的TimeBudget如果在给定的时间内依旧无法进行重试成功，则就会通过forget来删除对应的watcher， 由此针对消费特别缓慢的watcher则可以通过后续的重试来重新建立watch，从而减小对apiserver的watch压力。\n4.5 bookmark机制 #   bookmark机制是大阿里提供的一种优化方案，其核心是为了避免单个某个资源一直没有对应的事件，此时对应的informer的revision会落后集群很大，bookmark通过构建一种BookMark类型的事件来进行revision的传递，从而让informer在重启后不至于落后特别多。\n4.6 watchCache中的ringbuffer #   watchCache中通过store来构建了对应的索引缓存，但是在listwatch操作的时候，则通常需要获取某个revision后的所有数据，针对这类数据watchCache中则构建了一个ringbuffer来进行历史数据的缓存。\n5. 设计总结 #   本文介绍了kubernetes针对etcd的watch场景，k8s在性能优化上面的一些设计，逐个介绍缓存、定时器、序列化缓存、bookmark机制、forget机制、针对数据的索引与ringbuffer等组件的场景以及解决的问题，希望能帮助到那些对apiserver中的watch机制实现感兴趣的朋友。\n"});index.add({'id':2,'href':'/docs/kubernetes/sig-node/topology-manager/','title':"kubelet topology manager",'section':"sig-node",'content':" 注：本文翻译自 Node Topology Manager\n 1. 概要 #  越来越多的系统将CPU和硬件加速器组合使用，以支撑高延迟和搞吞吐量的并行计算。包括电信、科学计算、机器学习、金融服务和数据分析等领域的工作。这种的混血儿构成了一个高性能环境。\n为了达到最优性能，需要对CPU隔离、内存和设备的物理位置进行优化。然而，在kubernetes中，这些优化没有一个统一的组件管理。\n本次建议提供一个新机制，可以协同kubernetes各个组件，对硬件资源的分配可以有不同的细粒度。\n2. 启发 #  当前，kubelet中多个组件决定系统拓扑相关的分配：\n CPU 管理器  CPU管理器限制容器可以使用的CPU。该能力，在1.8只实现了一种策略——静态分配。该策略不支持在容器的生命周期内，动态上下线CPU。   设备管理器  设备管理器将某个具体的设备分配给有该设备需求的容器。设备通常是在外围互连线上。如果设备管理器和CPU管理器策略不一致，那么CPU和设备之间的所有通信都可能导致处理器互连结构上的额外跳转。   容器运行时（CNI）  网络接口控制器，包括SR-IOV虚拟功能（VF）和套接字有亲和关系，socket不同，性能不同。    相关问题：\n  节点层级的硬件拓扑感知（包括NUMA）  发现节点的NUMA架构  绑定特定CPU支持虚拟函数  提议：CPU亲和与NUMA拓扑感知  注意，以上所有的关注点都只适用于多套接字系统。内核能从底层硬件接收精确的拓扑信息（通常是通过SLIT表），是正确操作的前提。更多信息请参考ACPI规范的5.2.16和5.2.17节。\n2.1 目标 #   根据CPU管理器和设备管理器的输入，给容器选择最优的NUMA亲和节点。 集成kubelet中其他支持拓扑感知的组件，提供一个统一的内部接口。  2.2 非目标 #   设备间连接：根据直接设备互连来决定设备分配。此问题不同于套接字局部性。设备间的拓扑关系，可以都在设备管理器中考虑，可以做到套接字的亲和性。实现这一策略，可以从逐渐支持任何设备之间的拓扑关系。 大页：本次提议有2个前提，一是集群中的节点已经预分配了大页；二是操作系统能给容器做好本地页分配（只需要本地内存节点上有空闲的大页即可） 容器网络接口：本次提议不包含修改CNI。但是，如果CNI后续支持拓扑管理，此次提出的方案应该具有良好的扩展性，以适配网络接口的局部性。对于特殊的网络需求，可以使用设备插件API作为临时方案，以减少网络接口的局限性。  2.3 用户故事 #  故事1: 快速虚拟化的网络功能\n要求在一个首选的NUMA节点上，既要“网络快”，又能自动完成各个组件（大页，cpu集，网络设备）的协同。在大多数场景下，只有极少数的NUMA节点才能满足。\n故事2: 加速神经网络训练\nNUMA节点中的已分配的CPU和设备，可满足神经网络训练的加速器和独占的CPU的需求，以达到性能最优。\n3. 提议 #  主要思想：两相拓扑一致性协议 拓扑亲和性在容器级别，与设备和CPU的亲和类似。在Pod准入期间，一个新组件可以从设备管理器和CPU管理器收集pod中每个容器的配置，这个组件名为拓扑管理器。当这些组件进行资源分配时，拓扑管理器扮演本地对齐的预分配角色。我们希望各个组件能利用pod中隐含的QoS类型进行优先级排序，以满足局部重要性最优。\n3.1 提议修改点 #  3.1.1 新概念：拓扑管理器 #  这个提议主要关注kubelet中一个新组件，叫做拓扑管理器。拓扑管理器实现了Pod的Admit()接口，并参与kubelet的对pod的准入。当Admit()方法被调用，拓扑管理器根据kubelet标志，逐个pod或逐个容器收集kubelet其他组件的的拓扑信息。\n如果提示不兼容，拓扑管理器可以选择拒绝pod，这是由kubelet配置的拓扑策略所决定的。拓扑管理器支持4中策略：none（默认）、best-erffort、restricted和single-numa-node。\n拓扑信息中包含了对本地资源的偏好。拓扑信息当前由以下组成：\n 位掩码表——可能满足请求的NUMA节点 首选属性  属性定义如下：  每个拓扑信息提供者，都有一个满足请求的可能资源分配，这样就可以尽可能减少NUMA节点数量（节点为空那样计算） 有一种可能的分配方式，相关NUMA节点联合总量，不大于任何个单个资源的的请求量      3.1.1.1 Pod的有效资源请求/限制 #  所有提供拓扑信息的组件，都应该先考虑资源的请求和限制，再计算得出可靠的拓扑提示，这个规则是由init容器的概念定义的。\npod对资源的请求和限制的有效值，由以下2个条件中较大的一个决定：\n 所有init容器中，请求或限制的最大值（max([]initcontainer.Request)，max([]initcontainer.Limit)） 所有应用的请求和限制的总和（sum([]containers.Request)，sum([]containers.Limit)）  下面这个例子简要说明它是如何工作的：\napiVersion: v1 kind: Pod metadata: name: example spec: containers: - name: appContainer1 resources: requests: cpu: 2 memory: 1G - name: appContainer2 resources: requests: cpu: 1 memory: 1G initContainers: - name: initContainer1 resources: requests: cpu: 2 memory: 1G - name: initContainer2 resources: requests: cpu: 2 memory: 3G #资源请求的有效值: CPU: 3, Memory: 3G debug/临时容器不能指定资源请求/限制，因为不会影响拓扑提示的结果。\n3.1.1.2 范围 #  拓扑管理器将根据新 kubelet 标志--topology-manager-scope 的值，尝试逐个 pod 或逐个容器地对资源进行对齐。该标志可以显示的值详细如下:\ncontainer(默认)：逐个容器地收集拓扑信息。然后，拓扑策略将为每个容器单独调整资源，只有调整成功，Pod准入成功。\npod：逐个Pod地收集拓扑信息。然后，拓扑策略将为所有容器集体调整资源，只有调整成功，Pod准入成功。\n3.1.1.3 策略 #  none(默认)：kubelet不会参考拓扑管理器的决定\nbest-effort：拓扑管理器会基于拓扑信息，给出首选分配。在此策略下，即使分配结果不合理，pod也成功准入。\nrestricted：与best-effort不同，在此策略下，如果分配结果不合理，pod会被拒绝。同时，因准入失败，进入Terminated状态。\nsingle-numa-node：拓扑管理器会在NUMA节点上强制执行资源分配，如果分配失败，pod会被拒绝。同时，因准入失败，进入Terminated状态。\n拓扑管理器组件默认被禁用，直到从 alpha 到 beta 级别解禁。\n3.1.1.4 亲和计算 #  拓扑管理策略基于收集的所有拓扑信息，执行亲和计算，然后决定接受或拒绝 pod。\n3.1.1.4.1 亲和算法 #   best-effort/restricted (亲和算法相同)   循环遍历所有拓扑信息提供者，并以列表保存每个信息源的返回 遍历步骤1中的列表，执行按位与运算，合并为单个亲和信息。如果循环中任何字段的亲和返回了false，则最终结果该字段也为false 返回的亲和信息的最小集  最小集意味着至少有一个NUMA节点满足资源请求   如果没有找到任何NUMA节点集的提示，则返回一个默认提示，该值包含了所有NUMA节点，并把首选设置为false。   single-numa-node   循环遍历所有拓扑信息提供者，并以列表保存每个信息源的返回 过滤步骤1中累积的列表，使其只包含具有单个NUMA节点和空NUMA节点的提示 遍历步骤1中的列表，执行按位与运算，合并为单个亲和信息。如果循环中任何字段的亲和返回了false，则最终结果该字段也为false 如果没有找到具有单NUMA节点集的提示，则返回一个默认提示，该提示包含所有NUMA节点集并且首选设置为 false。  3.1.1.4.2 策略决断 #   best-effort  总是遵循拓扑信息提示，准入pod   restricted  只有拓扑提示的首选字段为true，才准入pod   single-numa-node  既需要拓扑的首选字段为true，又需要位掩码设置为单个NUMA节点，才准入pod    3.1.1.5 新的接口 #  清单: 拓扑管理器和相关接口（示意图）\npackage bitmask // BitMask interface allows hint providers to create BitMasks for TopologyHints type BitMask interface { Add(sockets ...int) error Remove(sockets ...int) error And(masks ...BitMask) Or(masks ...BitMask) Clear() Fill() IsEqual(mask BitMask) bool IsEmpty() bool IsSet(socket int) bool IsNarrowerThan(mask BitMask) bool String() string Count() int GetSockets() []int } func NewBitMask(sockets ...int) (BitMask, error) { ... } package topologymanager // Manager interface provides methods for Kubelet to manage pod topology hints type Manager interface { // Implements pod admit handler interface  lifecycle.PodAdmitHandler // Adds a hint provider to manager to indicate the hint provider  //wants to be consoluted when making topology hints  AddHintProvider(HintProvider) // Adds pod to Manager for tracking  AddContainer(pod *v1.Pod, containerID string) error // Removes pod from Manager tracking  RemoveContainer(containerID string) error // Interface for storing pod topology hints  Store } // TopologyHint encodes locality to local resources. Each HintProvider provides // a list of these hints to the TopoologyManager for each container at pod // admission time. type TopologyHint struct { NUMANodeAffinity bitmask.BitMask // Preferred is set to true when the BitMask encodes a preferred  // allocation for the Container. It is set to false otherwise.  Preferred bool } // HintProvider is implemented by Kubelet components that make // topology-related resource assignments. The Topology Manager consults each // hint provider at pod admission time. type HintProvider interface { // GetTopologyHints returns a map of resource names with a list of possible  // resource allocations in terms of NUMA locality hints. Each hint  // is optionally marked \u0026#34;preferred\u0026#34; and indicates the set of NUMA nodes  // involved in the hypothetical allocation. The topology manager calls  // this function for each hint provider, and merges the hints to produce  // a consensus \u0026#34;best\u0026#34; hint. The hint providers may subsequently query the  // topology manager to influence actual resource assignment.  GetTopologyHints(pod v1.Pod, containerName string) map[string][]TopologyHint // GetPodLevelTopologyHints returns a map of resource names with a list of  // possible resource allocations in terms of NUMA locality hints.  // The returned map contains TopologyHint of requested resource by all containers  // in a pod spec.  GetPodLevelTopologyHints(pod *v1.Pod) map[string][]TopologyHint // Allocate triggers resource allocation to occur on the HintProvider after  // all hints have been gathered and the aggregated Hint is available via a  // call to Store.GetAffinity().  Allocate(pod *v1.Pod, container *v1.Container) error } // Store manages state related to the Topology Manager. type Store interface { // GetAffinity returns the preferred affinity as calculated by the  // TopologyManager across all hint providers for the supplied pod and  // container.  GetAffinity(podUID string, containerName string) TopologyHint } // Policy interface for Topology Manager Pod Admit Result type Policy interface { // Returns Policy Name  Name() string // Returns a merged TopologyHint based on input from hint providers  // and a Pod Admit Handler Response based on hints and policy type  Merge(providersHints []map[string][]TopologyHint) (TopologyHint, lifecycle.PodAdmitResult) } 图：拓扑管理器组件\n 图：拓扑管理器实例化并出现在pod准入生命周期中\n 3.1.2 特性门禁和kubelet启动参数 #  将添加一个特性门禁，控制拓扑管理器特性的启动。此门禁将在 Kubelet 启用，并在 Alpha 版本中默认关闭。\n  门禁定义建议：\n--feature-gate=TopologyManager=true\n  如上所述，kubelet还新增一个标志，用于标识拓扑管理器策略。默认策略将会是none。\n  策略标志建议：\n--topology-manager-policy=none|best-effort|restricted|single-numa-node\n  根据选择的策略，以下标志将确定应用策略的范围（逐个pod或逐个容器）。范围的默认值是container\n  范围标志建议：\n--topology-manager-scope=container|pod\n  3.1.3 现有组件变更 #    Kubelet 向拓扑管理器咨询 pod 准入(上面讨论过)\n  添加两个拓扑管理器接口的实现和一个特性门禁\n 当功能门被禁用时，尽可能保证拓扑管理器功能失效。 添加一个功能性拓扑管理器，用来查询拓扑信息，以便为每个容器计算首选套接字掩码。    CPU管理器添加2个方法：GetTopologyHints()和GetPodLevelTopologyHints()\n CPU管理器的static策略在决定CPU的亲和性是，调用拓扑管理器的GetAffinity()方法    设备管理器添加2个方法：GetTopologyHints()和GetPodLevelTopologyHints()\n 在设备插件接口的设备结构中添加 TopologyInfo。插件在枚举受支持的设备时应该能够确定 NUMA 节点。请参阅下面的协议差异。 设备管理器决定设备分配时，调用拓扑管理器的GetAffinity()方法    清单: 修改后的设备插件 gRPC 协议\ndiff --git a/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto b/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto index efbd72c133..f86a1a5512 100644 --- a/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto +++ b/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto @@ -73,6 +73,10 @@ message ListAndWatchResponse {  repeated Device devices = 1; } +message TopologyInfo { + repeated NUMANode nodes = 1; +} + +message NUMANode { + int64 ID = 1; +} +  /* E.g: * struct Device { * ID: \u0026#34;GPU-fef8089b-4820-abfc-e83e-94318197576e\u0026#34;, * State: \u0026#34;Healthy\u0026#34;, + * Topology: + * Nodes: + * ID: 1 @@ -85,6 +89,8 @@ message Device {  string ID = 1; // Health of the device, can be healthy or unhealthy, see constants.go string health = 2; +\t// Topology details of the device +\tTopologyInfo topology = 3;  } 图：拓扑管理器提示提供者注册\n 图：拓扑管理器从HintProvider获取拓扑提示\n 此外，我们提议将设备插件接口扩展为“最后一级”过滤器，以帮助影响设备管理器做出的总体分配决策。下面的差异显示了提议的改动：\ndiff --git a/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto b/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto index 758da317fe..1e55d9c541 100644 --- a/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto +++ b/pkg/kubelet/apis/deviceplugin/v1beta1/api.proto @@ -55,6 +55,11 @@ service DevicePlugin {  // returns the new list rpc ListAndWatch(Empty) returns (stream ListAndWatchResponse) {} + // GetPreferredAllocation returns a preferred set of devices to allocate + // from a list of available ones. The resulting preferred allocation is not + // guaranteed to be the allocation ultimately performed by the + // `devicemanager`. It is only designed to help the `devicemanager` make a + // more informed allocation decision when possible. + rpc GetPreferredAllocation(PreferredAllocationRequest) returns (PreferredAllocationResponse) {} +  // Allocate is called during container creation so that the Device // Plugin can run device specific operations and instruct Kubelet // of the steps to make the Device available in the container @@ -99,6 +104,31 @@ message PreStartContainerRequest {  message PreStartContainerResponse { } +// PreferredAllocationRequest is passed via a call to +// `GetPreferredAllocation()` at pod admission time. The device plugin should +// take the list of `available_deviceIDs` and calculate a preferred allocation +// of size `size` from them, making sure to include the set of devices listed +// in `must_include_deviceIDs`. +message PreferredAllocationRequest { + repeated string available_deviceIDs = 1; + repeated string must_include_deviceIDs = 2; + int32 size = 3; +} + +// PreferredAllocationResponse returns a preferred allocation, +// resulting from a PreferredAllocationRequest. +message PreferredAllocationResponse { + ContainerAllocateRequest preferred_allocation = 1; +} +  // - Allocate is expected to be called during pod creation since allocation // failures for any container would result in pod startup failure. // - Allocate allows kubelet to exposes additional artifacts in a pod\u0026#39;s 使用这个新的API调用，设备管理器将在Pod准入时调用一个插件，要求它从可用设备列表中获得一个给定大小的首选设备分配。pod中的每个容器都会调用一次。\n传给GetPreferredAllocation()方法的可用设备列表不一定与系统上可用的完整列表相匹配。相反，在考虑所有TopologyHint之后，设备管理器调用GetPreferredAllocation()方法，是最后一次筛选，方法执行结束必须要做出选择。因此，这个可用列表已经经过TopologyHint的预筛选。\n首选分配并不保证是最终由设备管理器执行的分配。它的设计只是为了帮助设备管理者在可能的情况下做出更明智的分配决策。\n在决定首选分配时，设备插件可能会考虑设备管理器不知道的内部拓扑约束。分配 NVIDIA 图形处理器对，总是包括一个 NVLINK，就是一个很好的例子。\n在一台8 GPU 的机器上，如果需要2个 GPU，NVLINK 提供的最佳连接对可能是：\n{{0,3}, {1,2}, {4,7}, {5,6}} 使用 GetPreferredAllocation () ，NVIDIA 设备插件可以将这些首选分配之一转发给设备管理器，如果仍然有合适的设备集可用的话。如果没有这些额外的信息，设备管理器最终会在 TopologyHint 过滤之后从可用的 gpu 列表中随机选择 gpu。这个 API 允许它最终以最小的成本执行更好的分配。\n"});index.add({'id':3,'href':'/docs/kubernetes/sig-scheduling/advanced-scheduling/','title':"高级调度",'section':"sig-scheduling",'content':"1. 使用taint和toleration阻止节点调度到特定节点 #  1.1 taint和toleration #  taint，是在不修改已有pod的前提下，通过在节点上添加污点信息，拒绝pod的部署。只有当一个pod容忍某个节点的taint时，才能被调度到此节点上。\n显示节点taint信息\nkubectl describe node master.k8s ... Name: master.k8s Role: Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/hostname=master.k8s Annotations: node.alpha.kubernetes.io/ttl=0 Taints: node-role.kubernetes.io/master:NoSchedule ... 主节点上包含一个污点，污点包含一个key和value，以及一个effect，格式为=:。上面的污点信息表示，key为node-role.kubernetes.io/master，value是空，effect是NoSchedule。\n显示pod tolerations\nkubectl describe pod kube-proxy-as92 -n kube-system ... Tolerations: node-role.kubernetes.io/master:=NoSchedule node.alpha.kubernetes.io/notReady=:Exists:NoExecute node.alpha.kubernetes.io/unreachable=:Exists:NoExecute ... 第一个toleration匹配了主节点的taint，表示允许这个pod调度到主节点上。\n了解污点效果 另外2个在kube-proxy pod上容忍定义了当前节点状态是没有ready或者是unreachable时，该pod允许运行在该节点上多长时间。 污点可以包含以下三种效果：\n NoSchedule，表示如果pod没有容忍此污点，将无法调度 PreferNoSchedule，是上面的宽松版本，如果没有其他节点可调度，依旧可以调度到本节点 NoExecute，上2个在调度期间起作用，而此设定也会影响正在运行中的pod。如果节点上的pod没有容忍此污点，会被驱逐。   1.2 在节点上定义污点 #  kubectl taint node node1.k8s node-type=production:NoSchedule 此命令给节点添加污点，key为node-type，value为production，effect为NoSchedule。如果现在部署一个常规pod多个副本，没有一个pod会调度到此节点上。\n1.3 在pod上添加容忍 #  apiVersion: apps/v1 kind: Deployment metadata: name: prod spec: replicas: 5 template: spec: ... tolertations: - key: node-type operator: Equals value: production effect: NoSchedule 部署此deployment，pod即可调度到node1.k8s节点上。\n1.4 了解污点和容忍的使用场景 #  调度时使用污点和容忍\n污点可以组织新pod的调度，或者定义非有限调度节点，甚至是将已有pod驱逐。例如，一个集群分成多个部分，只允许开发团队将pod部署到特定节点上；或者某些特殊pod依赖硬件配置。\n配置节点失效后的pod重新调度最长等待时间\n容忍程度也可以配置，当某个pod所在节点NotReady或者Unreachable是，k8s可以等待该pod重新调度之前的最长等待时间。\n... tolerations: - effect: NoExecute key: node.alpha.kubernetes.io/notReady operator: Exists tolerationSeconds: 300 - effect: NoExecute key: node.alpha.kubernetes.io/unreachable operator: Exists tolerationSeconds: 300 ... 上面2个容忍表示，该pod容忍所在节点处于notReady和unreachable状态维持300s。超时后，再重新调度。\n2. 使用节点亲和将pod调度到指定节点 #  污点可以拒绝调度，亲和允许调度。早期的k8s版本，节点亲和，就是pod中的nodeSelector字段。与节点选择器类似，每个节点都可以配置亲和性规则，可以是硬性标注，也可以是偏好。\n检查节点默认标签\nkubectl describe node gke-kubia-default-adj12knzf-2dascjb Name: gke-kubia-default-adj12knzf-2dascjb Role: Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux failure-domain.beta.kubernetes.io/region=europe-west1 failure-domain.beta.kubernetes.io/zone=europe-west1-d kubernetes.io/hostname=gke-kubia-default-adj12knzf-2dascjb 这是一个gke的节点，最后三个标签涉及到亲和性，分别表示所在地理地域，可用性区域，和主机名。\n2.1 指定强制节点亲和性规则 #  下面展示了只能被部署到含有gpu=true标签的节点上的pod：\napiVersion: v1 kind: Pod metadata: name: kubia-gpu spec: affinity: nodeAffinity: requiredDuringSchdulingIgnoredDuringExecution: lableSelectorTerms: - matchExpressions: - key: gpu operator: In values: - \u0026#34;true\u0026#34; 较长的节点亲和性属性名的含义\n requireDuringScheduling\u0026hellip;表示该字段下定义的规则，为了让pod调度到该节点上，必须满足的标签。 \u0026hellip;IgnoredDuringExecution表明该字段下的规则，不会影响已经在节点上的pod  了解节点选择器的条件\nlableSelectorTerms和matchExpressions定义了节点的标签必须满足哪一种表达方式。\n2.2 调度pod时优先考虑某些节点 #  节点亲和性和节点选择器相比，最大的好处就是，当调度某一个pod，指定可以优先考某些节点，如果节点均无法满足，调度结果也是可以接受的。这是由preferdDuringSchdulingIgnoredDuringExecution字段实现的。\n添加标签\nkubectl label node node1.k8s availability-zone=zone1 kubectl label node node1.k8s share-type=dedicated kubectl label node node2.k8s availability-zone=zone2 kubectl label node node2.k8s share-type=shared 指定优先级节点亲和性\napiVersion: apps/v1 kind: Deployment metadata: name: pref spec: template: ... spec: affinity: nodeAffinity: prefereddDuringSchdulingIgnoredDuringExecution: - weight: 80 preference: - matchExpressions: - key: availability-zone operator: In values: - zone1 - weight: 20 preference: - matchExpressions: - key: share-type operator: In values: - dedicated 上面描述一个节点亲和优先级，并不是强制要求。想要pod调度到含有availability-zone=zone1和share-type=dedicated的节点上。第一个优先级相对重要，weight=80，第二个相对不重要，weight=20。\n了解优先级是如何工作的\n如果集群中包含很多节点，上面的deployment，将会把节点分成四种。2个标签都包含的，优秀级最高；只包含weight=80的标签节点次之；然后只是包含weight=20的节点；剩下的节点排在最后。\n在一个包含2个节点的集群中部署\n如果在只有node1和node2的集群中部署一个replica=5的deployment，pod更多部署到node1，有极少数调度到node2上。这是因为kube-schduler除了节点亲和的优先级函数，还有其他函数来决定pod调度到哪里。其中之一就是Selector SpreadPriority函数，此函数保证同一个ReplicaSet或者Service的pod，将分散到不同节点上。避免单个节点失效而出现整个服务挂掉。\n3. 使用pod亲和和反亲和部署pod #  刚才描述了pod和节点之间的亲和关系，也有pod与pod之间的亲和关系，例如前端pod和后端pod，尽可能部署较近，减少网络时延。\n3.1 使用pod亲和将多个pod部署到同一个节点上 #  部署1个后端pod和5个前端pod。先部署后端：\nkubectl run backend -l app=backend --image busybox --sleep 9999 这里没什么也别，只是给pod加了个标签，app=backend。\n在pod中指定亲和性\napiVersion: apps/v1 kind: Deployment metadata: name: frontend spec: replicas: 5 template: ... spec: affinity: podAffinity: requireddDuringSchdulingIgnoredDuringExecution: - topologyKey: kubernetes.io/hostname labelSelector: matchLabels: app: backend 这里强制要求，frontend的pod被调度到和其他包含app=backend标签的pod所在的相同节点上。这是通过topologyKey指定的。\n了解调度器如何使用pod亲和规则\n上面的应用部署后，5个前端pod和1个后端pod都在node2上。假设后端pod被误删，重新调度后，依旧在node2上。虽然后端pod本身没有定义任何亲和性规则，如果调度到其他节点，即会打破已有的亲和规则。\n3.2 将pod部署到同一个机柜、可用性区域或者地理地域 #  同一个可用性区域协调部署\n如果想要pod在同一个available zone部署应用，可以将topologyKey设置成failure-domain.beta.kubernetes.io/zone。\n同一个地域协调部署 如果想要pod在同一个available zone部署应用，可以将topologyKey设置成failure-domain.beta.kubernetes.io/region。\n了解topologyKey如何工作 topologyKey的工作方式很简单，上面提到的三个属性并没有什么特别。可以设置成任意你想要的值。\n当调度器决定决定pod调度到哪里时，首先检查podAffinity配置，选择满足条件的pod，接着查询这些pod运行在那些节点上。特别寻找能匹配podAffinity配置的topologyKey的节点。接着，会优先选择所有标签匹配的pod的值的节点。\n3.3 pod优先级亲和性 #  与节点亲和一样，pod之间也可以用prefereddDuringSchdulingIgnoredDuringExecution。\napiVersion: apps/v1 kind: Deployment metadata: name: frontend spec: replicas: 5 template: ... spec: affinity: podAffinity: prefereddDuringSchdulingIgnoredDuringExecution: - weight: 80 podAffinityTerm: topologyKey: kubernetes.io/hostname labelSelector: matchLabels: app: backend 和nodeAffinity一样，设置了权重。也需要设置topologyKey和labelSelector。\n3.4 pod反亲和分开调度pod #  同理，有nodeAntiAffinity，也有podAntiAffinity。这将导致调度器永远不会选择包含podAntiAffinity的pod所在的节点。\n使用反亲和分散pod\napiVersion: apps/v1 kind: Deployment metadata: name: frontend spec: replicas: 5 template: metadata: labels: app: frontend spec: affinity: podAffinity: requiredDuringSchdulingIgnoredDuringExecution: topologyKey: kubernetes.io/hostname labelSelector: matchLabels: app: frontend 上面的deployment创建后，5个实例应当分布在5个不同节点上。\n理解pod反亲和优先级\n在这种情况下，可能使用软反亲和策略（prefereddDuringSchdulingIgnoredDuringExecution）。毕竟2个前端pod在同一个节点上也不是什么问题。如果运行在一个节点上出现问题，那么使用requiredDuringSchdulingIgnoredDuringExecution就比较合适了。\n与pod亲和一样，topologyKey决定了pod不能被调度的范围。\n"});index.add({'id':4,'href':'/docs/kubernetes/sig-network/learn-about-Service/','title':"深入了解 Service",'section':"sig-network",'content':"一、基本概念 #  1.1 Service 定义详解 #  Service 是对一组提供相同功能的 Pods 的抽象，并为它们提供一个统一的入口。借助 Service，应用可以方便的实现服务发现与负载均衡，并实现应用的零宕机升级。Service 通过标签来选取服务后端，一般配合 Replication Controller 或者 Deployment 来保证后端容器的正常运行。这些匹配标签的 Pod IP 和端口列表组成 endpoints，由 kube-proxy 负责将服务 IP 负载均衡到这些 endpoints 上。\napiVersion: v1 kind: Service metadata: name: string namespace: string labels: - name: string annotations: - name: string spec: selector: [] type: string // ClusterIP、NodePort、LoadBalancer clusterIP: string // type=ClusterIP, 有自动分配的能力；type=LoadBalancer，需指定 sessionAffinity: string // 是否支持session，默认为空，可选值ClutserIP，同一个client的request，都发送到同一个后端pod ports: - name: string protocol: string // tcp、udp，默认tcp port: int targetPort: int nodePort: int status: // spec.type=LoadBalancer,设置外部负载均衡器地址，用于公有云环境 loadBalancer: ingress: ip: string hostname: string 1.2 Service 分类 #   ClusterIP：默认类型，自动分配一个仅 cluster 内部可以访问的虚拟 IP NodePort：在 ClusterIP 基础上为 Service 在每台机器上绑定一个端口，这样就可以通过 http://\u0026lt;NodeIP\u0026gt;:NodePort 来访问该服务。如果 kube-proxy 设置了 --nodeport-addresses=10.240.0.0/16（v1.10 支持），那么仅该 NodePort 仅对设置在范围内的 IP 有效。 LoadBalancer：在 NodePort 的基础上，借助 cloud provider 创建一个外部的负载均衡器，并将请求转发到 \u0026lt;NodeIP\u0026gt;:NodePort ExternalName：将服务通过 DNS CNAME 记录方式转发到指定的域名（通过 spec.externlName 设定）。需要 kube-dns 版本在 1.7 以上。  二、Service 基本用法 #  一般来说，对外提供服务的应用程序需要通过某种机制来实现，对 于容器应用最简便的方式就是通过TCP/IP机制及监听IP和端口号来实现。\n直接通过Pod的IP地址和端口号可以访问到容器应用内的服务，但是Pod的IP地址是不可靠的，例如当Pod所在的Node发生故障时，Pod将被Kubernetes重新调度到另一个Node，Pod的IP地址将发生变化。更重要的是，如果容器应用本身是分布式的部署方式，通过多个实例共同提供服务，就需要在这些实例的前端设置一个负载均衡器来实现请求的分发。Kubernetes中的Service就是用于解决这些问题的核心组件。\nService定义中的关键字段是ports和selector。通过selector与pod关联，port描述service本身的端口，targetPort表示流量转发的端口，也就是pod的端口，从而完成访问service负载均衡到后端任意一个pod。Kubernetes 提供了两种负载分发策略：RoundRobin和SessionAffinity，具体说明如 下。\n RoundRobin：轮询模式，即轮询将请求转发到后端的各个Pod 上。 SessionAffinity：基于客户端IP地址进行会话保持的模式，即第 1 次将某个客户端发起的请求转发到后端的某个Pod上，之后从相同的客 户端发起的请求都将被转发到后端相同的Pod上。  在默认情况下，Kubernetes采用RoundRobin模式对客户端请求进行负载分发，但我们也可以通过设置service.spec.sessionAffinity=ClientIP来 启用SessionAffinity策略。这样，同一个客户端IP发来的请求就会被转发 到后端固定的某个Pod上了。\n2.1 集群内访问集群外服务 #  到现在为止，我们己经讨论了后端是集群中运行的一个或多个pod 的服务。但也存在希望通过Kubernetes 服务特性暴露外部服务的情况。不要让服务将连接重定向到集群中的pod，而是让它重定向到外部 IP 和端口。这样做可以让你充分利用服务负载平衡和服务发现。在集群中运行的客户端 pod 可以像连接到内部服务一样连接到外部服务。\n首先要知道，service和pod并不是直接相连的，此二者之间还有一个对象叫endpoint。service根据selector找到后端pod，用pod IP和端口创建与service同名的endpoint，记录pod IP。当pod异常被删除重建后，获得的新地址，只需要更新endpoint中记录的pod IP即可。因此，想要访问集群外部的服务，可手动配置service的endpoint。\n2.1.1 创建没有selector的Service #   创建没有selector的Service  apiVersion: v1 kind: Service metadata: name: external-service spec: ports: - port: 80 为没有选择器的服务创建Endpoint资源  apiVersion: v1 kind: Endpoint metadata: name: external-service // endpoint的名称必须和服务的名称相匹配 subsets: - addresses: - ip: 11.11.11.11 // 将service重定向到endpoint的地址 - ip: 22.22.22.22 ports: - port: 80 // endpoint目标端口 Endpoint对象需要与服务具有相同的名称，并包含该服务的目标IP地址和端口列表。服务和Endpoint资源都发布到服务器后，这样服务就可以像具有pod选择器那样的服务正常使用。在服务创建后创建的容器将包含服务的环境变量，并且与其IP : port对的所有连接都将在服务端点之间进行负载均衡。\n2.1.2 创建ExternalName的service #  除了手动配置服务的Endpoint来代替公开外部服务方法，有一种更简单的方法，就是通过其完全限定域名(FQDN)访问外部服务。\n要创建一个具有别名的外部服务的服务时，要将创建服务资源的一个type字段设置为ExternalName。例如，设想一下在api.somecompany.com上有公共可用的API可以定义一个指向它的服务，如下面的代码清单所示。\napiVersion: v1 kind: Service metadata: name: external-service spec: type: ExternalName externalName: someapi.somecompany.com ports: - port: 80 服务创建完成后，pod可以通过external-service.default.svc. cluster.local域名(甚至是external-service)连接到外部服务，而不 是使用服务的实际FQDN。这隐藏了实际的服务名称及其使用该服务的pod 的位置，允许修改服务定义，并且在以后如果将其指向不同的服务，只需简单地修改externalName属性，或者将类型重新变回Cluster IP并为服务创建Endpoint——无论是手动创建，还是对服务上指定标签选择器使其自动创建。\nExternalName服务仅在DNS级别实施——为服务创建了简单的CNAME DNS记录。因此，连接到服务的客户端将直接连接到外部服务，完全绕过服务代理。出于这个原因，这些类型的服务甚至不会获得集群IP。\n2.2 集群外访问集群内服务 #  2.2.1 NodePort服务 #  将服务的类型设置成NodePort：每个集群节点都会在节点上打开一个端口，对于NodePort服务，每个集群节点在节点本身(因此得名叫NodePort)上打开一个端口，并将在该端口上接收到的流量重定向到基础服务。该服务仅在内部集群IP和端口上才可访间，但也可通过所有节点上的专用端口访问。\napiVersion: v1 kind: Service metadata: name: kubia-nodeport spec: type: NodePort ports: - port: 80 targetPort: 8080 nodePort: 30123 selector: app: kubia 2.2.2 LoadBalancer服务 #  在云提供商上运行的Kubernetes集群通常支持从云基础架构自动提供负载平衡器。所有需要做的就是设置服务的类型为LoadBadancer而不是NodePort。负载均衡器拥有自己独一无二的可公开访问的IP地址，并将所有连接重定向到服务。可以通过负载均衡器的IP地址访问服务。\n如果Kubemetes在不支持LoadBadancer服务的环境中运行，则不会调配负载平衡器，但该服务仍将表现得像一个NodePort服务。这是因为LoadBadancer服务是NodePort服务的扩展。\napiVersion: v1 kind: Service metadata: name: kubia-loadbalancer spec: type: LoadBalancer ports: - port: 80 targetPort: 8080 selector: app: kubia clusterIP: 10.0.171.239 loadBalancerIP: 78.11.24.19 status: loadBalancer: ingress: - ip: 146.148.47.155 三、通过Ingress暴露服务 #   为什么需要Ingress？  一个重要的原因是每个LoadBalancer服务都需要自己的负载均衡器，以及独有的公有IP地址，而Ingress只需要一个公网IP就能为许多服务提供访问。当客户端向Ingress发送HTTP请求时，Ingress会根据请求的主机名和路径决定请求转发到的服务。\n3.1 创建Ingress Controller和默认的backend服务 #  在定义Ingress策略之前，需要先部署Ingress Controller，以实现为所有后端Service都提供一个统一的入口。Ingress Controller需要实现基于不同HTTP URL向后转发的负载分发规则，并可以灵活设置7层负载分发策略。如果公有云服务商能够提供该类型的HTTP路由LoadBalancer，则也可设置其为Ingress Controller。\n在Kubernetes中，Ingress Controller将以Pod的形式运行，监控API Server的/ingress接口后端的backend services，如果Service发生变化，则Ingress Controller应自动更新其转发规则。\n下面的例子使用Nginx来实现一个Ingress Controller，需要实现的基本逻辑如下。\n 监听API Server，获取全部Ingress的定义。 基于Ingress的定义，生成Nginx所需的配置文件/etc/nginx/nginx.conf。 执行nginx -s reload命令，重新加载nginx.conf配置文件的内容。  为了让Ingress Controller正常启动，还需要为它配置一个默认的backend，用于在客户端访问的URL地址不存在时，返回一个正确的404应答。这个backend服务用任何应用实现都可以，只要满足对根路径“/”的访问返回404应答，并且提供/healthz路径以使kubelet完成对它的健康检查。另外，由于Nginx通过default-backend-service的服务名称（Service Name）去访问它，所以需要DNS服务正确运行。\n3.2 创建ingress资源 #  3.2.1 转发到单个后端服务上 #  基于这种设置，客户端到Ingress Controller的访问请求都将被转发到后端的唯一Service上，在这种情况下Ingress无须定义任何rule。\n通过如下所示的设置，对Ingress Controller的访问请求都将被转发到“myweb:8080”这个服务上。\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test-ingress spec: backend: serviceName: webapp servicePort: 8080 3.2.2 将不同的服务映射到相同主机的不同路径： #  这种配置常用于一个网站通过不同的路径提供不同的服务的场景，例如/web表示访问Web页面，/api表示访问API接口，对应到后端的两个服务，通过Ingress的设置很容易就能将基于URL路径的转发规则定义出来。\n通过如下所示的设置，对 mywebsite.com/web 的访问请求将被转发到 web-service:80 服务上；对 mywebsite.com/api 的访问请求将被转发到 api-service:80 服务上：\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test-ingress spec rules: - host mywebsite.com http: paths: - path: /web backend: serviceName: web-service servicePort: 80 - path: /api backend: serviceName: api-service servicePort: 80 3.2.3 不同的域名(虚拟主机名)被转发到不同的服务上 #  这种配置常用于一个网站通过不同的域名或虚拟主机名提供不同服务的场景，例如foo.example.com域名由foo提供服务，bar.example.com域名由bar提供服务。\n通过如下所示的设置，对“foo.example.com”的访问请求将被转发到“foo:80”服务上，对“bar.example.com”的访问请求将被转发到“bar:80”服务上：\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test-ingress spec: rules: - host: foo.example.com http: paths: - path: I backend: serviceName: foo servicePort: 80 - host: bar.example.com http: paths: - path: I backend: serviceName: bar servicePort: 80 3.2.4 不使用域名的转发规则 #  这种配置用于一个网站不使用域名直接提供服务的场景，此时通过任意一台运行ingress-controller的Node都能访问到后端的服务。\n下面的配置为将“/demo”的访问请求转发到“webapp:8080/demo”服务上：\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test-ingress spec: rules: - http: paths: - path: /demo backend: serviceName: webapp servicePort: 8080 注意，使用无域名的Ingress转发规则时，将默认禁用非安全HTTP，强制启用HTTPS。可以在Ingress的定义中设置一个annotation[ingress.kubernetes.io/ssl-redirect: \u0026ldquo;false\u0026rdquo;]来关闭强制启用HTTPS的设置：\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test-ingress annotations: ingress.kubernetes.io/ssl-redirect: \u0026#34;false\u0026#34; spec: rules: - http: paths: - path: /demo backend: serviceName: webapp servicePort: 8080 3.3 Ingress的TLS安全设置 #  当客户端创建到Ingress控制器的TLS连接时，控制器将终止TLS连接。客户端和控制器之间的通信是加密的，而控制器和后端pod之间的通信则不是运行在pod上的应用程序不需要支持TLS。例如，如果pod运行web服务器，则它只能接收HTTP通信，并让Ingress控制器负责处理与TLS相关的所有内容。要使控制器能够这样做，需要将证书和私钥附加到Ingress。这两个必需资源存储在称为Secret的Kubernetes资源中，然后在Ingress manifest 中引用它。\n为了Ingress提供HTTPS的安全访问，可以为Ingress中的域名进行TLS安全证书的设置。设置的步骤如下。\n 创建自签名的密钥和SSL证书文件  openssl genrsa -out tls.key 2048 openssl req -new - x509 -key tls.key -out tls.cert -days 360 -subject/CN=kubia.example.com 将证书保存到Kubernetes中的一个Secret资源对象上  kubectl create secret tls mywebsite-tls-secret --cert=tls.cert --key=tls.key 将该Secret对象设置到Ingress中  apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: mywebsite-ingress-tls spec: tls: - hosts: - mywebsite.com secretName: mywebsite-tls-secret rules: - http: paths: - path: /demo backend: serviceName: webapp servicePort: 8080 根据提供服务的网站域名是一个还是多个，可以使用不同的操作完成前两步SSL证书和Secret对象的创建，在只有一个域名的情况下设置相对简单。第3步对于这两种场景来说是相同的。\n"});index.add({'id':5,'href':'/docs/kubernetes/sig-node/kubelet-eviction-manager/','title':"kubelet eviction manager",'section':"sig-node",'content':"1、概述 #  在可用计算资源较少时，kubelet为保证节点稳定性，会主动地结束一个或多个pod以回收短缺地资源，这在处理内存和磁盘这种不可压缩资源时，驱逐pod回收资源的策略，显得尤为重要。下面来具体研究下Kubelet Eviction Policy的工作机制。\n kubelet预先监控本节点的资源使用，防止资源被耗尽，保证节点稳定性。 kubelet会预先Fail N(\u0026gt;=1)个Pod，以回收出现紧缺的资源。 kubelet在Fail一个pod时，kill掉pod内所有container，并设置pod.status.phase = Failed。 kubelet按照事先设定好的Eviction Threshold来触发驱逐动作，实现资源回收。  1.1 驱逐信号 #  在源码pkg/kubelet/eviction/api/types.go中定义了以下及几种Eviction Signals：\n   Eviction Signal Description     memory.available := node.status.capacity[memory] - node.stats.memory.workingSet   nodefs.available := node.stats.fs.available   nodefs.inodesFree := node.stats.fs.inodesFree   imagefs.available := node.stats.runtime.imagefs.available   imagefs.inodesFree := node.stats.runtime.imagefs.inodesFree   allocatableMemory.available := pod.allocatable - pod.workingSet   pid.available := node.MaxPID - node.NumOfRunningProcesses    上表主要涉及三个方面，memory、file system和pid。其中kubelet值支持2种文件系统分区：\n nodefs：kubelet用来存储volume和daemon logs等 imagesfs：容器运行时(docker等)用来保存镜像和容器的writable layer  1.2 驱逐阈值 #  kubelet的入参接收用户定义的eviction signal和eviction threshold的映射关系，格式如下：\n[eviction-signal] [opterator] [quantity]\n 支持的signal如上表所示； operator是关系运算符，例如\u0026lt;； quantity是驱逐阈值，合法的值必须是kubernetes使用的数量表示，例如1Gi和10%等；  1.2.1 软驱逐策略 #  Soft Eviction Thresholds，它与以下三个参数配合使用：\n eviction-soft：(e.g. memory.available\u0026lt;1.5Gi) 触发软驱逐的阈值； eviction-soft-grace-period：(e.g. memory.available=1m30s) 当达到软驱逐的阈值，需要等待的时间；在这段时间内，每10s会重新获取监控数据并更新threshold值，如果在等待期间，最后一次的数据仍然超过阈值，才会触发驱逐pod的行为。 eviction-max-pod-grace-period：(e.g. 30s) 当满足软驱逐阈值并终止 pod 时允许的最大宽限期值。如果待Evict的Pod指定了pod.Spec.TerminationGracePeriodSeconds，则取min(eviction-max-pod-grace-period, pod.Spec.TerminationGracePeriodSeconds)作为Pod Termination真正的Grace Period。  因此，在软驱逐策略下，从kubelet检测到驱逐信号达到了阈值设定开始，到pod真正被kill掉，共花费的时间是：sum(eviction-max-pod-grace-period, min(eviction-max-pod-grace-period, pod.Spec.TerminationGracePeriodSeconds))\n1.2.2 硬驱逐 #  Hard Eviction Thresholds比Soft Eviction Thresholds简单粗暴，没有宽限期，即使pod配置了pod.Spec.TerminationGracePeriodSeconds，一旦达到阈值配置，kubelet立马回收关联的短缺资源，并且使用的就立即结束，而不是优雅终止。此特性已经标记为Deprecated。\n源码pkg/kubelet/apis/config/v1beta1/defaults_linux.go给出了默认的硬驱逐配置：\n memory.available \u0026lt; 100Mi nodefs.available \u0026lt; 10% nodefs.inodesFree \u0026lt; 5% imagefs.available \u0026lt; 15%  1.3 驱逐周期 #  有了驱逐信号和阈值，也有了策略，接下来就是Eviction Monitoring Interval。kubelet对应的监控周期，就通过cAdvisor的housekeeping-interval配置的，默认10s。\n1.4 节点状态 #  kubelet监测到配置的驱逐策略被触发，会将驱逐信号映射到对应的节点状态。Kubelet会将对应的Eviction Signals映射到对应的Node Conditions，源码[pkg/kubelet/eviction/helpers.go]，其映射关系如下：\n   节点状态 驱逐信号 描述     MemoryPressure memory.avaliable, allocatableMemory.available 节点或pod的可用内存触发驱逐阈值   DiskPressure nodefs.avaliable, nodefs.inodesFree, imagefs.available, imagesfs.inodesFree 节点的root fs或image fs上的可用磁盘空间和索引节点已满足收回阈值   PIDPressure pid.available 节点的可用PID触发驱逐阈值    kubelet映射了Node Condition之后，会继续按照--node-status-update-frequency(default 10s)配置的时间间隔，周期性的与kube-apiserver进行node status updates。\n1.5 节点状态振荡 #  ​\t考虑这样一种场景，节点上监控到soft eviction signal的值，始终在eviction threshold上下波动，那么kubelet就会将该node对应的node condition在true和false之间来回切换。给kube-scheduler产生错误的调度结果。\n​\t因此，kubelet添加参数eviction-pressure-transition-period(default 5m0s)配置，使Kubelet在解除由Evicion Signal映射的Node Pressure之前，必须等待5分钟。\n​\t驱逐逻辑添加了一步：\n Soft Evction Singal高于Soft Eviction Thresholds时，Kubelet还是会立刻设置对应的MemoryPressure或DiskPressure为True。 当MemoryPressure或DiskPressure为True的前提下，发生了Soft Evction Singal低于Soft Eviction Thresholds的情况，则需要等待eviction-pressure-transition-period(default 5m0s)配置的这么长时间，才会将condition pressure切换回False。  一句话总结：Node Condition Pressure成为True容易，切换回False则要等eviction-pressure-transition-period。\n1.6 回收节点层级资源 #  如果满足驱逐阈值并超过了宽限期，kubelet将启动回收压力资源的过程，直到它发现低于设定阈值的信号为止。kubelet将尝试在驱逐终端用户 pod 前回收节点层级资源。发现磁盘压力时，如果节点针对容器运行时配置有独占的 imagefs，kubelet回收节点层级资源的方式将会不同。\n1.6.1 使用imagefs #   如果 nodefs 文件系统满足驱逐阈值，kubelet通过驱逐 pod 及其容器来释放磁盘空间。 如果 imagefs 文件系统满足驱逐阈值，kubelet通过删除所有未使用的镜像来释放磁盘空间。  1.6.2 未使用imagefs #   删除停止运行的pod/container 删除全部没有被使用的镜像  1.7 驱逐策略 #  ​\tkubelet根据Pod的QoS Class实现了一套默认的Evication策略，kubelet 首先根据他们对短缺资源的使用是否超过请求来排除 pod 的驱逐行为，然后通过 优先级，然后通过相对于 pod 的调度请求消耗急需的计算资源。图解如下：\n ​\t对于每一种Resource都可以将容器分为3中QoS Classes: Guaranteed, Burstable, and Best-Effort，它们的QoS级别依次递减。\n BestEffort，按照短缺资源占用量排序，占用量越高，被kill的优先级越高； Burstable，对使用量高于请求量的pod排序，占用越多，回收优先级越高；如果没有pod的使用超过请求，按照BestEffort策略回收； Guaranteed，Guaranteed pod 只有为所有的容器指定了要求和限制并且它们相等时才能得到保证。由于另一个 pod 的资源消耗，这些 pod 保证永远不会被驱逐。如果系统守护进程（例如 kubelet、docker、和 journald）消耗的资源多于通过 system-reserved 或 kube-reserved 分配保留的资源，并且该节点只有 Guaranteed 或 Burstable pod 使用少于剩余的请求，然后节点必须选择驱逐这样的 pod 以保持节点的稳定性并限制意外消耗对其他 pod 的影响。在这种情况下，它将首先驱逐优先级最低的 pod。  1.8 最小驱逐回收 #  有些情况下，可能只回收一小部分的资源就能使得Evication Signal的值低于eviction thresholds。但是，可能随着资源使用的波动或者新的调度Pod使得在该Node上很快又会触发evict pods的动作，eviction毕竟是耗时的动作，所以应该尽量避免这种情况的发生。\n为了减少这类问题，每次Evict Pods后，Node上对应的Resource不仅要比Eviction Thresholds低，还要保证最少比Eviction Thresholds，再低--eviction-minimum-reclaim中配置的数量。\n例如使用下面的配置：\n--eviction-hard=memory.available\u0026lt;500Mi,nodefs.available\u0026lt;1Gi,imagefs.available\u0026lt;100Gi --eviction-minimum-reclaim=\u0026#34;memory.available=0Mi,nodefs.available=500Mi,imagefs.available=2Gi\u0026#34; 如果 memory.available 驱逐阈值被触发，kubelet将保证 memory.available 至少为 500Mi。对于 nodefs.available，kubelet将保证 nodefs.available 至少为 1.5Gi。对于 imagefs.available，kubelet将保证 imagefs.available 至少为 102Gi，直到不再有相关资源报告压力为止。\n所有资源的默认 eviction-minimum-reclaim 值为 0。\n"});index.add({'id':6,'href':'/menu/','title':"Menu",'section':"介绍",'content':"  kubernetes   SIG-API-Machinery  SIG-Apps  SIG-Scheduling  SIG-Node  SIG-Network    "});})();